{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rephrasing Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torch\n",
    "# %pip install peft\n",
    "# %pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftConfig, PeftModel\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   # bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "'''I'm checking your data: \n",
    " \n",
    " - from Apr 27 2024 \n",
    " \n",
    " and getting the insights... ğŸ”''',\n",
    "'''I'm checking your data: \n",
    " \n",
    " - from Apr 22 2024 to Apr 28 2024 \n",
    " \n",
    " and getting the insights... ğŸ”''',\n",
    "'''I'm analysing your data: \n",
    " \n",
    " - from Mar 01 2024 to Mar 31 2024 \n",
    " - and from Apr 01 2024 to Apr 30 2024 \n",
    " \n",
    " and checking what changed... ğŸ”''',\n",
    "'''Your diary looks empty for this period ğŸ¤”''',\n",
    "'''come back when you put some data in your diary â˜ºï¸''',\n",
    "'''Ok, let me analyse your data some more... ğŸ”''',\n",
    "'''Okay, will be back soon with more info... ğŸ”''',\n",
    "'''(Advanced analysis requires time, I'll be back when I'm done...)''',\n",
    "'''(This may take some time, I'll send you a message when it's done...)''',\n",
    "'''âš  WARNING:  you're comparing two periods with different lenghts. The comparison might be unsafe.''',\n",
    "'''Some days at the beginning and/or end are missing. ğŸ§ \n",
    " \n",
    " I removed these for you: \n",
    " - Mar 01 - Mar 05''',\n",
    "'''âš  FOOD: In the chart below you can see how different foods contributes to your intake:''',\n",
    "'''âš  TREND: you should get more carbohydrates, but you're slightly decreasing it .\n",
    " It would be better to revert this. ğŸ§ ''',\n",
    "'''âš  CONSISTENCY: Your daily intake seems pretty variable: try to eat similar amounts every day. ğŸ§''',\n",
    "'''âœ… TREND: you should get more sodium, in fact you're lightly increasing it .\n",
    " This is the right way to go. â˜ºï¸ \n",
    " \n",
    " âš  CONSISTENCY: I see high variability in your daily intake: you should try to avoid changing it so often ğŸ§''',\n",
    "'''âš  TREND: you should keep your actual energy intake, instead you're slightly decreasing it .\n",
    " This is ok for now but better stabilise it to preserve this result ğŸ¤” \n",
    " ğŸ“ˆ PROGRESS: The trend is about the same as before ğŸ¤” \n",
    " \n",
    " âœ… CONSISTENCY: Your daily intake looks regular, good job! ğŸ˜ \n",
    " ğŸ“ˆ PROGRESS: The consistency didn't really change ğŸ¤”''',\n",
    "'''ğŸ– PROTEIN ğŸ– \n",
    " \n",
    " âš  ON AVERAGE: You had 83% (17% deficit). It should be more, we'll have to work on it. ğŸ§\n",
    " \n",
    " \n",
    " âš  TOUGHEST DAY: April 28, your intake was 52% (48% missing). It's not enough, we have to address this. ğŸ§''',\n",
    "'''ğŸ¬ SUGAR ğŸ¬ \n",
    " \n",
    " âš  ON AVERAGE: You got 55% (45% missing). You need to increase it, we have to address this. ğŸ¤”\n",
    " \n",
    " \n",
    " âš  TOUGHEST DAY: April 26, your intake was 32% (68% missing). It's not enough, we have to address this. ğŸ¤”''',\n",
    "'''ğŸ”¥ ENERGY ğŸ”¥ \n",
    " \n",
    " âœ… ON AVERAGE: I see a good balance in your energy intake. Well done! ğŸ˜ƒ \n",
    " ğŸ“ˆ PROGRESS: The average energy intake is about the same as before ğŸ§ \n",
    " \n",
    " âš  TOUGHEST DAY: April 17, your intake was 51% (49% missing). It's not enough, we have to address this. ğŸ§\n",
    " ğŸ“ˆ PROGRESS: The intake for most off-plan day is about the same as before ğŸ§''',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPHRASING_PROMPT = \"Rephrase the following message to the user, keeping any mentioned dates. Do not introduce new dates or assume time periods. Do not add extra information. Use emojis.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output(messages, model, tokenizer):\n",
    "    for message in messages:\n",
    "        print('input:', message)\n",
    "        context = [\n",
    "            {\"role\": \"system\", \"content\": REPHRASING_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": message},\n",
    "        ]\n",
    "\n",
    "        input_ids = tokenizer.apply_chat_template(\n",
    "            context,\n",
    "            add_generation_prompt=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(model.device)\n",
    "\n",
    "        terminators = [\n",
    "            tokenizer.eos_token_id,\n",
    "            tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "        ]\n",
    "\n",
    "        outputs = model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=256,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=terminators,\n",
    "            do_sample=True,\n",
    "            temperature=0.6,\n",
    "            top_p=0.9,\n",
    "        )\n",
    "        response = outputs[0][input_ids.shape[-1]:]\n",
    "        print('output:', tokenizer.decode(response, skip_special_tokens=True))\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def generate_ollama_output(model, message):\n",
    "    print('input:', message)\n",
    "\n",
    "    url = 'http://localhost:11434/api/generate'\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"system\": REPHRASING_PROMPT,\n",
    "        \"prompt\": message,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.6\n",
    "        },\n",
    "        \"stream\": False\n",
    "    }\n",
    "    payload_json = json.dumps(payload, ensure_ascii=False)\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    response = requests.post(url, data=payload_json.encode('utf-8'), headers=headers)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        output = json.loads(response.content.decode('utf-8'))['response']\n",
    "        print('output:', output)\n",
    "        print()\n",
    "    else:\n",
    "        print(\"Error in rephrasing request:\", response.status_code, 'response:', response.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3 loaded into memory: {\"model\":\"llama3\",\"created_at\":\"2025-05-16T08:53:16.653140204Z\",\"response\":\"\",\"done\":true,\"done_reason\":\"load\"}\n"
     ]
    }
   ],
   "source": [
    "url = 'http://localhost:11434/api/generate'\n",
    "payload_json = json.dumps({\"model\": \"llama3\"})\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "response = requests.post(url, data=payload_json.encode('utf-8'), headers=headers)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    print('llama3 loaded into memory:', response.content.decode('utf-8'))\n",
    "else:\n",
    "    print(\"Error in rephrasing request:\", response.status_code, 'response:', response.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: I'm checking your data: \n",
      " \n",
      " - from Apr 27 2024 \n",
      " \n",
      " and getting the insights... ğŸ”\n",
      "output: ğŸ“Š I'm analyzing your data from April 27, 2024... ğŸ”\n",
      "\n",
      "input: I'm checking your data: \n",
      " \n",
      " - from Apr 22 2024 to Apr 28 2024 \n",
      " \n",
      " and getting the insights... ğŸ”\n",
      "output: ğŸ“Š I'm analyzing your data from Apr 22 2024 to Apr 28 2024... ğŸ”\n",
      "\n",
      "input: I'm analysing your data: \n",
      " \n",
      " - from Mar 01 2024 to Mar 31 2024 \n",
      " - and from Apr 01 2024 to Apr 30 2024 \n",
      " \n",
      " and checking what changed... ğŸ”\n",
      "output: ğŸ“Š I'm reviewing your data from March 1st, 2024 to March 31st, 2024 and from April 1st, 2024 to April 30th, 2024. ğŸ”\n",
      "\n",
      "input: Your diary looks empty for this period ğŸ¤”\n",
      "output: ğŸ“… Your diary looks empty for this period ğŸ¤”\n",
      "\n",
      "input: come back when you put some data in your diary â˜ºï¸\n",
      "output: Come back when you fill in your diary ğŸ“…â˜ºï¸\n",
      "\n",
      "input: Ok, let me analyse your data some more... ğŸ”\n",
      "output: ğŸ” I'm taking a closer look at your data... ğŸ”\n",
      "\n",
      "input: Okay, will be back soon with more info... ğŸ”\n",
      "output: ğŸ‘‹ I'll be back soon with more info... ğŸ”\n",
      "\n",
      "input: (Advanced analysis requires time, I'll be back when I'm done...)\n",
      "output: ğŸ•°ï¸ I'm crunching some numbers... I'll be back when I'm done! ğŸ“Š\n",
      "\n",
      "input: (This may take some time, I'll send you a message when it's done...)\n",
      "output: ğŸ•’ï¸ Working on it... I'll send you a message when it's complete! ğŸ“±\n",
      "\n",
      "input: âš  WARNING:  you're comparing two periods with different lenghts. The comparison might be unsafe.\n",
      "output: âš ï¸ Warning: Be cautious when comparing periods of different lengths!\n",
      "\n",
      "input: Some days at the beginning and/or end are missing. ğŸ§ \n",
      " \n",
      " I removed these for you: \n",
      " - Mar 01 - Mar 05\n",
      "output: ğŸ“… Some days are missing at the beginning and/or end. ğŸ§\n",
      "\n",
      "input: âš  FOOD: In the chart below you can see how different foods contributes to your intake:\n",
      "output: ğŸ´ FOOD: Check out the chart below to see how various foods impact your diet:\n",
      "\n",
      "input: âš  TREND: you should get more carbohydrates, but you're slightly decreasing it .\n",
      " It would be better to revert this. ğŸ§ \n",
      "output: ğŸš¨ Reminder: You're decreasing your carbohydrate intake, but it's recommended to increase it instead! ğŸ\n",
      "\n",
      "input: âš  CONSISTENCY: Your daily intake seems pretty variable: try to eat similar amounts every day. ğŸ§\n",
      "output: ğŸ“Š Reminder: Try to eat similar amounts every day! ğŸ´\n",
      "\n",
      "input: âœ… TREND: you should get more sodium, in fact you're lightly increasing it .\n",
      " This is the right way to go. â˜ºï¸ \n",
      " \n",
      " âš  CONSISTENCY: I see high variability in your daily intake: you should try to avoid changing it so often ğŸ§\n",
      "output: âœ… Good job increasing your sodium intake! ğŸ‘\n",
      "\n",
      "âš ï¸ Remember to keep your daily intake consistent, though - try not to make too many changes! ğŸ¤”\n",
      "\n",
      "input: âš  TREND: you should keep your actual energy intake, instead you're slightly decreasing it .\n",
      " This is ok for now but better stabilise it to preserve this result ğŸ¤” \n",
      " ğŸ“ˆ PROGRESS: The trend is about the same as before ğŸ¤” \n",
      " \n",
      " âœ… CONSISTENCY: Your daily intake looks regular, good job! ğŸ˜ \n",
      " ğŸ“ˆ PROGRESS: The consistency didn't really change ğŸ¤”\n",
      "output: âš ï¸ Trend: Your energy intake is slightly decreasing, but it's okay for now. Try to stabilize it to keep the result! ğŸ¤”\n",
      "ğŸ“ˆ Progress: The trend remains the same as before ğŸ¤”\n",
      "âœ… Consistency: Your daily intake is regular, great job! ğŸ˜\n",
      "ğŸ“ˆ Progress: The consistency remains the same ğŸ¤”\n",
      "\n",
      "input: ğŸ– PROTEIN ğŸ– \n",
      " \n",
      " âš  ON AVERAGE: You had 83% (17% deficit). It should be more, we'll have to work on it. ğŸ§\n",
      " \n",
      " \n",
      " âš  TOUGHEST DAY: April 28, your intake was 52% (48% missing). It's not enough, we have to address this. ğŸ§\n",
      "output: ğŸ– PROTEIN ğŸ–\n",
      "\n",
      "âš ï¸ Attention! ğŸ‘€\n",
      "Your average protein intake is 17% below target, and we need to improve it. ğŸ’ª\n",
      "On April 28, it was particularly challenging, with only 52% of your daily target met. Let's work on boosting that number! ğŸ’ª\n",
      "\n",
      "input: ğŸ¬ SUGAR ğŸ¬ \n",
      " \n",
      " âš  ON AVERAGE: You got 55% (45% missing). You need to increase it, we have to address this. ğŸ¤”\n",
      " \n",
      " \n",
      " âš  TOUGHEST DAY: April 26, your intake was 32% (68% missing). It's not enough, we have to address this. ğŸ¤”\n",
      "output: ğŸ¬ SUGAR ğŸ¬\n",
      "\n",
      "âš ï¸ Average sugar intake: 55% (45% missing) ğŸ¤”\n",
      "âš ï¸ Toughest day: April 26, 32% (68% missing) ğŸ¤”\n",
      "\n",
      "input: ğŸ”¥ ENERGY ğŸ”¥ \n",
      " \n",
      " âœ… ON AVERAGE: I see a good balance in your energy intake. Well done! ğŸ˜ƒ \n",
      " ğŸ“ˆ PROGRESS: The average energy intake is about the same as before ğŸ§ \n",
      " \n",
      " âš  TOUGHEST DAY: April 17, your intake was 51% (49% missing). It's not enough, we have to address this. ğŸ§\n",
      " ğŸ“ˆ PROGRESS: The intake for most off-plan day is about the same as before ğŸ§\n",
      "output: ğŸ”¥ ENERGY ğŸ”¥\n",
      "\n",
      "ğŸ‘ Good job maintaining a balanced energy intake! ğŸ˜ƒ\n",
      "\n",
      "ğŸ“ˆ Your energy intake has remained consistent since before.\n",
      "\n",
      "âš ï¸ Be aware that on April 17, your intake was only 51% of what was needed. Let's work on improving that! ğŸ§\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_output(messages, model, tokenizer) # 9:20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-bit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:29<00:00,  7.33s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    quantization_config=bnb_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                #     print('input:', output)\n",
    "                #     context = [\n",
    "                #         {\"role\": \"system\", \"content\": REPHRASING_PROMPT},\n",
    "                #         {\"role\": \"user\", \"content\": output},\n",
    "                #     ]\n",
    "\n",
    "                #     input_ids = rephrasing_tokenizer.apply_chat_template(\n",
    "                #         context,\n",
    "                #         add_generation_prompt=True,\n",
    "                #         return_tensors=\"pt\"\n",
    "                #     ).to(rephrasing_model.device)\n",
    "\n",
    "                #     terminators = [\n",
    "                #         rephrasing_tokenizer.eos_token_id,\n",
    "                #         rephrasing_tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "                #     ]\n",
    "\n",
    "                #     outputs = rephrasing_model.generate(\n",
    "                #         input_ids,\n",
    "                #         max_new_tokens=256,\n",
    "                #         eos_token_id=terminators,\n",
    "                #         do_sample=True,\n",
    "                #         temperature=0.6,\n",
    "                #         top_p=0.9,\n",
    "                #     )\n",
    "                #     response = outputs[0][input_ids.shape[-1]:]\n",
    "                #     output = rephrasing_tokenizer.decode(response, skip_special_tokens=True)\n",
    "\n",
    "                #     # use message in quotes if quotes present\n",
    "                #     if '\"' in output:\n",
    "                #         open_quote_pos = output.index('\"')\n",
    "                #         if '\"' in output[open_quote_pos:]:\n",
    "                #             end_quote_pos = output[open_quote_pos:].index('\"')\n",
    "                #             output = output[open_quote_pos:end_quote_pos]\n",
    "\n",
    "                #     print('output:', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: I'm checking your data: \n",
      " \n",
      " - from Apr 27 2024 \n",
      " \n",
      " and getting the insights... ğŸ”\n",
      "output: ğŸ” I'm analyzing your data from April 27, 2024...\n",
      "\n",
      "input: I'm checking your data: \n",
      " \n",
      " - from Apr 22 2024 to Apr 28 2024 \n",
      " \n",
      " and getting the insights... ğŸ”\n",
      "output: ğŸ” I'm analyzing your data from April 22, 2024 to April 28, 2024...\n",
      "\n",
      "input: I'm analysing your data: \n",
      " \n",
      " - from Mar 01 2024 to Mar 31 2024 \n",
      " - and from Apr 01 2024 to Apr 30 2024 \n",
      " \n",
      " and checking what changed... ğŸ”\n",
      "output: ğŸ“Š I'm reviewing your data from March 1st, 2024 to March 31st, 2024 and April 1st, 2024 to April 30th, 2024. ğŸ”\n",
      "\n",
      "input: Your diary looks empty for this period ğŸ¤”\n",
      "output: Your diary looks empty for now ğŸ¤”\n",
      "\n",
      "input: come back when you put some data in your diary â˜ºï¸\n",
      "output: ğŸ“† Come back when you've filled in your diary! â˜ºï¸\n",
      "\n",
      "input: Ok, let me analyse your data some more... ğŸ”\n",
      "output: ğŸ” I'm still reviewing your information...\n",
      "\n",
      "input: Okay, will be back soon with more info... ğŸ”\n",
      "output: ğŸ‘‹ See you soon! ğŸ”\n",
      "\n",
      "input: (Advanced analysis requires time, I'll be back when I'm done...)\n",
      "output: \"ğŸ•’ï¸ I'm crunching some numbers, I'll be back when my advanced analysis is complete... ğŸ‘‹\"\n",
      "\n",
      "input: (This may take some time, I'll send you a message when it's done...)\n",
      "output: ğŸ“± \"Your request is being processed. I'll send you a message when it's complete...\"\n",
      "\n",
      "input: âš  WARNING:  you're comparing two periods with different lenghts. The comparison might be unsafe.\n",
      "output: ğŸš¨ Warning: Be careful when comparing periods of different lengths! âš \n",
      "\n",
      "input: Some days at the beginning and/or end are missing. ğŸ§ \n",
      " \n",
      " I removed these for you: \n",
      " - Mar 01 - Mar 05\n",
      "output: Some days at the beginning and/or end are missing. ğŸ§\n",
      "\n",
      "input: âš  FOOD: In the chart below you can see how different foods contributes to your intake:\n",
      "output: ğŸ”ğŸŸ Did you know that the chart below shows how different foods impact your daily intake?\n",
      "\n",
      "input: âš  TREND: you should get more carbohydrates, but you're slightly decreasing it .\n",
      " It would be better to revert this. ğŸ§ \n",
      "output: âš ï¸ Reminder: you're reducing your carbohydrate intake, but it's recommended to increase it instead. ğŸ§\n",
      "\n",
      "input: âš  CONSISTENCY: Your daily intake seems pretty variable: try to eat similar amounts every day. ğŸ§\n",
      "output: ğŸš¨ Reminder: Try to maintain a consistent daily food intake, same as before â°.\n",
      "\n",
      "input: âœ… TREND: you should get more sodium, in fact you're lightly increasing it .\n",
      " This is the right way to go. â˜ºï¸ \n",
      " \n",
      " âš  CONSISTENCY: I see high variability in your daily intake: you should try to avoid changing it so often ğŸ§\n",
      "output: ğŸ‘€ Trend Alert: Good job on increasing your sodium intake! ğŸ‰\n",
      "\n",
      "ğŸš¨ Consistency Check: Let's work on stabilizing your daily sodium intake to avoid frequent changes. ğŸ˜Š\n",
      "\n",
      "input: âš  TREND: you should keep your actual energy intake, instead you're slightly decreasing it .\n",
      " This is ok for now but better stabilise it to preserve this result ğŸ¤” \n",
      " ğŸ“ˆ PROGRESS: The trend is about the same as before ğŸ¤” \n",
      " \n",
      " âœ… CONSISTENCY: Your daily intake looks regular, good job! ğŸ˜ \n",
      " ğŸ“ˆ PROGRESS: The consistency didn't really change ğŸ¤”\n",
      "output: ğŸ¤” Trend Alert: ğŸ‘€ You're slightly decreasing your energy intake, but it's okay for now. Let's stabilize it to keep the results! ğŸ“ˆ\n",
      "\n",
      "ğŸ“Š Progress Report: The trend is steady, just like before ğŸ¤”\n",
      "\n",
      "ğŸ‰ Consistency Champion: Your daily intake is looking regular and good job! ğŸ˜\n",
      "\n",
      "ğŸ¤” Progress Update: The consistency hasn't changed much ğŸ“ˆ\n",
      "\n",
      "input: ğŸ– PROTEIN ğŸ– \n",
      " \n",
      " âš  ON AVERAGE: You had 83% (17% deficit). It should be more, we'll have to work on it. ğŸ§\n",
      " \n",
      " \n",
      " âš  TOUGHEST DAY: April 28, your intake was 52% (48% missing). It's not enough, we have to address this. ğŸ§\n",
      "output: ğŸ– PROTEIN ğŸ–\n",
      "\n",
      "âš ï¸ Attention! ğŸ‘€\n",
      "\n",
      "You had an average protein intake of 83% below your target, which is a 17% deficit. ğŸ¤• We need to work on this! ğŸ’ª\n",
      "\n",
      "And, on April 28, your protein intake was particularly low, at only 52% of your target. This is a 48% shortfall. ğŸš¨ We need to address this! ğŸ’ª\n",
      "\n",
      "input: ğŸ¬ SUGAR ğŸ¬ \n",
      " \n",
      " âš  ON AVERAGE: You got 55% (45% missing). You need to increase it, we have to address this. ğŸ¤”\n",
      " \n",
      " \n",
      " âš  TOUGHEST DAY: April 26, your intake was 32% (68% missing). It's not enough, we have to address this. ğŸ¤”\n",
      "output: ğŸ¬ SUGAR ğŸ¬\n",
      "\n",
      "âš  Important reminder: You've been missing your sugar intake goal. On average, you've been getting 55% of what you need. We need to improve this! ğŸ¤”\n",
      "\n",
      "âš  Specifically, on April 26, you only got 32% of your daily sugar intake. Let's work on increasing this! ğŸ¤”\n",
      "\n",
      "input: ğŸ”¥ ENERGY ğŸ”¥ \n",
      " \n",
      " âœ… ON AVERAGE: I see a good balance in your energy intake. Well done! ğŸ˜ƒ \n",
      " ğŸ“ˆ PROGRESS: The average energy intake is about the same as before ğŸ§ \n",
      " \n",
      " âš  TOUGHEST DAY: April 17, your intake was 51% (49% missing). It's not enough, we have to address this. ğŸ§\n",
      " ğŸ“ˆ PROGRESS: The intake for most off-plan day is about the same as before ğŸ§\n",
      "output: ğŸ”¥ ENERGY ğŸ”¥\n",
      "\n",
      "ğŸ‘ You're doing great! Your average energy intake is balanced. ğŸ™Œ\n",
      "\n",
      "ğŸ“ˆ Your progress is steady, with no significant changes. ğŸ“Š\n",
      "\n",
      "âš ï¸ However, on April 17, your energy intake was only 51%, which is a concern. Let's work on improving this. ğŸ’ª\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_output(messages, model, tokenizer) # 2:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-bit, Static kv-cache and torch.compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:44<00:00, 11.25s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.bfloat16)\n",
    "model.generation_config.cache_implementation = \"static\"\n",
    "model = torch.compile(model, mode=\"reduce-overhead\", fullgraph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output(messages, model, tokenizer):\n",
    "    for message in messages:\n",
    "        print('input:', message)\n",
    "        context = [\n",
    "            {\"role\": \"system\", \"content\": REPHRASING_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": message},\n",
    "        ]\n",
    "\n",
    "        input_ids = tokenizer.apply_chat_template(\n",
    "            context,\n",
    "            add_generation_prompt=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(model.device)\n",
    "\n",
    "        terminators = [\n",
    "            tokenizer.eos_token_id,\n",
    "            tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "        ]\n",
    "\n",
    "        outputs = model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=256,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=terminators,\n",
    "            do_sample=True,\n",
    "            temperature=0.6,\n",
    "            top_p=0.9,\n",
    "        )\n",
    "        response = outputs[0][input_ids.shape[-1]:]\n",
    "        print('output:', tokenizer.decode(response, skip_special_tokens=True))\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_output(messages, model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-bit and Flash Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    load_in_4bit=True,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_output(messages, model, tokenizer) # 2:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "# counselling\n",
    "# ('Would you like some help with a struggle?', 'counselling'),\n",
    "# ('Hmm... Would you like to try explaining again? It can help to give some extra sentences to describe your problem!', 'retry_counselling'),\n",
    "# ('Was this helpful?', 'ask_feedback'),\n",
    "\n",
    "# prompting\n",
    "# (\"Hey! I noticed that your food diary from yesterday is still empty... It's important to log your foods while you still remember what you've eaten!\", 'check_diary'),\n",
    "# (\"Hey! I noticed a food entry with more than 1 kilogram in your food diary yesterday... Maybe double check to see if everything's logged correctly?\", 'check_diary'),\n",
    "# (\"Hey! I noticed a food entry with more than 2 litres in your food diary yesterday... Maybe double check to see if everything's logged correctly?\", 'check_diary'),\n",
    "# (\"Hey! I noticed a food entry with more than 4 cups in your food diary yesterday... Maybe double check to see if everything's logged correctly?\", 'check_diary'),\n",
    "# (\"Hey! I noticed a food entry with more than half your calorie goal in your food diary yesterday... Maybe double check to see if everything's logged correctly?\", 'check_diary'),\n",
    "# (\"Hey! I noticed less than 4 food entries in your food diary yesterday... Maybe double check to see if everything's logged correctly?\", 'check_diary'),\n",
    "# (\"Hey! I noticed less than half of your calorie goal in your food diary yesterday... Maybe double check to see if everything's logged correctly?\", 'check_diary'),\n",
    "# (\"Hey! I noticed more than twice your calorie goal in your food diary yesterday... Maybe double check to see if everything's logged correctly?\", 'check_diary'),\n",
    "\n",
    "# no_dates\n",
    "# ('*****no_dates*****', False),\n",
    "# ('''My apologies, but I don't get what time you asked for ğŸ˜•''', 'no_dates'),\n",
    "# ('''For dates, this is the format I understand:\n",
    "#  - day: numbers (0-31)\n",
    "#  - months: the name either full or abbreviated (e.g.: January or Jan)\n",
    "#  - year: complete year (e.g.: 2005)\n",
    "\n",
    "# #  For example I'll understand: Jan 10 2005! ğŸ˜Š''', 'no_dates'),\n",
    "\n",
    "# no_multiple_times\n",
    "# ('*****no_multiple_times*****', False),\n",
    "# ('''That's more than one time period, I can't do that. ğŸ§''', 'no_multiple_times'),\n",
    "# ('''I can't provide insights for multiple time periods ğŸ§''', 'no_multiple_times'),\n",
    "# ('''But I can provide comparisons! Try something like \"Compare today with yesterday\" â˜ºï¸''', 'no_multiple_times'),\n",
    "# ('''Perhaps you're looking for comparisons, like \"Was this week better than last week\"? ğŸ˜„''', 'no_multiple_times'),\n",
    "\n",
    "# wait\n",
    "# ('*****wait*****', False),\n",
    "# ('''I'm checking your data: \n",
    " \n",
    "#  - from Apr 27 2024 \n",
    " \n",
    "#  and getting the insights... ğŸ”''', 'wait'),\n",
    "# ('''I'm checking your data: \n",
    " \n",
    "#  - from Apr 22 2024 to Apr 28 2024 \n",
    " \n",
    "#  and getting the insights... ğŸ”''', 'wait'),\n",
    "# ('''I'm analysing your data: \n",
    " \n",
    "#  - from Mar 01 2024 to Mar 31 2024 \n",
    "#  - and from Apr 01 2024 to Apr 30 2024 \n",
    " \n",
    "#  and checking what changed... ğŸ”''', 'wait'),\n",
    "# ('''I'm analysing your data:\n",
    "\n",
    "#  - about *energy*\n",
    "#  - *from Apr 22 2024 to Apr 28 2024*\n",
    "\n",
    "#  and getting the insights... ğŸ”''', 'wait'),\n",
    "# ('''I'm analysing your data:\n",
    "\n",
    "#  - about *sodium*\n",
    "#  - *from Apr 22 2024 to Apr 28 2024*\n",
    "\n",
    "#  and getting the insights... ğŸ”''', 'wait'),\n",
    "\n",
    "# wait_more\n",
    "# ('*****wait_more*****', False),\n",
    "# ('''Ok, let me analyse your data some more... ğŸ”''', 'wait_more'),\n",
    "# ('''Okay, will be back soon with more info... ğŸ”''', 'wait_more'),\n",
    "# ('''(Advanced analysis requires time, I'll be back when I'm done...)''', 'wait_more'),\n",
    "# ('''(This may take some time, I'll send you a message when it's done...)''', 'wait_more'),\n",
    "\n",
    "# empty\n",
    "('*****empty*****', False),\n",
    "('''Your diary looks empty for this period ğŸ¤”''', 'empty'),\n",
    "('''I see...no data this period ğŸ§''', 'empty'),\n",
    "('''come back when you put some data in your diary â˜ºï¸''', 'empty'),\n",
    "('''I can't help you until you've filled your diary â˜ºï¸''', 'empty'),\n",
    "\n",
    "# holes_inside_warn\n",
    "('*****holes_inside_warn*****', False),\n",
    "('''Some days are missing. I can estimate them but the final value could be different to reality. Would you like me to estimate your data?''', 'holes_inside_warn'),\n",
    "('''âš  *ATTENTION: SOME DATA ARE ESTIMATED* âš \n",
    " *You've made me *approximate some data* because they were missing. The values you see *might be less accurate*.*\n",
    " Also, you won't be able to view advanced insights, as this wouldn't be safe for you.''', 'holes_inside_warn'),\n",
    "\n",
    "# holes_surrounding_warn\n",
    "('*****holes_surrounding_warn*****', False),\n",
    "('''Some days at the beginning and/or end are missing. ğŸ§ \n",
    " \n",
    " I removed these for you: \n",
    " - Mar 01 - Mar 05''', 'holes_surrounding_warn'),\n",
    "\n",
    "# most_data_missing\n",
    "('*****most_data_missing*****', False),\n",
    "('''Most of the days in that period are empty, so I'm sorry to say that I can't do that. ğŸ˜”''', 'most_data_missing'),\n",
    "('''Go fill the empty days and try again ğŸ˜''', 'most_data_missing'),\n",
    "\n",
    "# query_complexity_excess\n",
    "('*****query_complexity_excess*****', False),\n",
    "('''That's too hard for me, my time limit is 5 months ğŸ˜…''', 'query_complexity_excess'),\n",
    "\n",
    "# update\n",
    "('*****update*****', False, False),\n",
    "('''ğŸ”¥ *ENERGY* ğŸ”¥\n",
    "\n",
    " âš  *ON AVERAGE:* You had *61% (39% missing)*. You need to increase it, we'll have to work on it. ğŸ§\n",
    "\n",
    "\n",
    " âš  *TOUGHEST DAY:* I'm sorry but with only one day I can't tell you this ğŸ˜•''', 'update', 'energy'),\n",
    "('''ğŸ”¥ *ENERGY* ğŸ”¥\n",
    "\n",
    " âœ… *ON AVERAGE:* I see a good balance in your energy intake. That's great! ğŸ˜Š\n",
    "\n",
    " âš  *TOUGHEST DAY:* April 17, your intake was *51% (49% missing)*. It needs to be higher, we'll have to work on it. ğŸ§''', 'update', 'energy'),\n",
    "('''âš  *TREND:* you should keep your actual energy intake, unfortunately you're lightly reducing it .\n",
    " This is ok for now but try stabilising this or it could affect your diet ğŸ¤¨\n",
    "\n",
    " âœ… *CONSISTENCY:* Your daily intake looks regular, nice work! ğŸ™‚''', 'update', 'energy'),\n",
    "('''âš  FOOD: In the chart below you can see how different foods contributes to your intake:''', 'update', 'energy'),\n",
    "('''âš  *TREND AND CONSISTENCY:* sorry, I need 3 or more days for this ğŸ˜•''', 'update', 'carbohydrates'),\n",
    "('''âš  TREND: you should get more carbohydrates, but you're slightly decreasing it .\n",
    " It would be better to revert this. ğŸ§ \n",
    " \n",
    " âš  CONSISTENCY: Your daily intake seems pretty variable: try to eat similar amounts every day. ğŸ§''', 'update', 'carbohydrates'),\n",
    "('''âœ… TREND: you should get more sodium, in fact you're lightly increasing it .\n",
    " This is the right way to go. â˜ºï¸ \n",
    " \n",
    " âš  CONSISTENCY: I see high variability in your daily intake: you should try to avoid changing it so often ğŸ§''', 'update', 'sodium'),\n",
    "('''ğŸ– PROTEIN ğŸ– \n",
    " \n",
    " âš  ON AVERAGE: You had 83% (17% deficit). It should be more, we'll have to work on it. ğŸ§\n",
    " \n",
    " \n",
    " âš  TOUGHEST DAY: April 28, your intake was 52% (48% missing). It's not enough, we have to address this. ğŸ§''', 'update', 'protein'),\n",
    "('''ğŸ¬ SUGAR ğŸ¬ \n",
    " \n",
    " âš  ON AVERAGE: You got 55% (45% missing). You need to increase it, we have to address this. ğŸ¤”\n",
    " \n",
    " \n",
    " âš  TOUGHEST DAY: April 26, your intake was 32% (68% missing). It's not enough, we have to address this. ğŸ¤”''', 'update', 'sugar'),\n",
    "\n",
    "# filter_more_info_button\n",
    "('*****filter_more_info_button*****', False),\n",
    "('''ğŸ”¥ ENERGY ğŸ”¥\n",
    " What do you want to know? ğŸ¤”\n",
    "\n",
    " Tap anything you need (tap again to cancel) and confirm when ready ğŸ˜„''', 'filter_more_info_button'),\n",
    "('''ğŸ§ˆ FAT ğŸ§ˆ\n",
    " What do you want to know? ğŸ¤”''', 'filter_more_info_button'),\n",
    "\n",
    "# empty_message_stack\n",
    "('*****empty_message_stack*****', False),\n",
    "('''Sure, let's stop here ğŸ™‚''', 'empty_message_stack'),\n",
    "('''3,2,1....all gone!''', 'empty_message_stack'),\n",
    "('''Ok, let\\'s forget about that''', 'empty_message_stack'),\n",
    "\n",
    "# weird_comparison\n",
    "('*****weird_comparison*****', False),\n",
    "('''âš  WARNING:  you're comparing two periods with different lengths. The comparison might be unsafe.''', 'weird_comparison'),\n",
    "('''âš  *WARNING: * these periods have some *days in common*. The comparison might be unsafe.''', 'weird_comparison'),\n",
    "('''âš  *WARNING: * you *cut out some days* between the two periods. The comparison might be unsafe.''', 'weird_comparison'),\n",
    "\n",
    "# compare\n",
    "('*****compare*****', False, False),\n",
    "('''âš  TREND: you should keep your actual energy intake, instead you're slightly decreasing it .\n",
    " This is ok for now but better stabilise it to preserve this result ğŸ¤” \n",
    " ğŸ“ˆ PROGRESS: The trend is about the same as before ğŸ¤” \n",
    " \n",
    " âœ… CONSISTENCY: Your daily intake looks regular, good job! ğŸ˜ \n",
    " ğŸ“ˆ PROGRESS: The consistency didn't really change ğŸ¤”''', 'compare', 'energy'),\n",
    "('''ğŸ”¥ ENERGY ğŸ”¥ \n",
    " \n",
    " âœ… ON AVERAGE: I see a good balance in your energy intake. Well done! ğŸ˜ƒ \n",
    " ğŸ“ˆ PROGRESS: The average energy intake is about the same as before ğŸ§ \n",
    " \n",
    " âš  TOUGHEST DAY: April 17, your intake was 51% (49% missing). It's not enough, we have to address this. ğŸ§\n",
    " ğŸ“ˆ PROGRESS: The intake for most off-plan day is about the same as before ğŸ§''', 'compare', 'energy'),\n",
    "\n",
    "# compare no dates\n",
    "('Please give me two dates or a date range to compare', 'compare_no_dates'),\n",
    "('''It looks like you've only given me one date or date range! Could you give me two to compare?''', 'compare_one_date'),\n",
    "('''I'm sorry, but I can only compare two dates or date ranges''', 'compare_many_dates'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ('''ğŸ”¥ *ENERGY* ğŸ”¥\n",
    "\n",
    " âš  *ON AVERAGE:* Your intake was *15% more than your goal*. It needs to be lower, we have to address this. ğŸ¤¨\n",
    "\n",
    "\n",
    " âš  *TOUGHEST DAY:* sorry, I need at least two days to get this ğŸ˜•''', 'update', 'energy'),\n",
    "    ('''âš  *TREND AND CONSISTENCY:* for this I need at least 3 days, sorry ğŸ˜•''', 'update', 'sugar'),\n",
    "    ('''âš  *FOOD*: In the below chart you can see how different foods contribute to your intake:''', 'update', 'sodium'),\n",
    "    ('''ğŸ *CARBOHYDRATES* ğŸ\n",
    "\n",
    " âš  *ON AVERAGE:* You got *67% (33% missing)*. It's not enough, we have to address this. ğŸ§\n",
    "\n",
    "\n",
    " âš  *TOUGHEST DAY:* sorry, I need at least two days to get this ğŸ˜•''', 'update', 'carbohydrates'),\n",
    "    ('''ğŸ¬ *SUGAR* ğŸ¬\n",
    "\n",
    " âœ… *ON AVERAGE:* I see a good balance in your sugar intake. That's great! ğŸ˜\n",
    "\n",
    " âš  *TOUGHEST DAY:* May 05, your intake was *73% (27% missing)*. You need to increase it, we have to address this. ğŸ§''', 'update', 'sugar'),\n",
    "    ('''âš  *TREND:* you should keep your actual energy intake, instead you're lightly reducing it .\n",
    " It's ok for now but try stabilising this or it could affect your diet ğŸ¤¨\n",
    "\n",
    " âš  *CONSISTENCY:* Your daily intake seems pretty variable: you should try to regularise it. ğŸ¤¨''', 'update', 'energy'),\n",
    "    ('''âœ… *FOOD*: In the chart below you can see how different foods contribute to your intake:''', 'update', 'energy'),\n",
    "    ('''ğŸ§ˆ *FAT* ğŸ§ˆ\n",
    "\n",
    " âš  *ON AVERAGE:* You got *84% (16% deficit)*. It needs to be higher, we have to address this. ğŸ¤¨\n",
    " ğŸ“ˆ *PROGRESS:* The average fat intake didn't really change ğŸ¤¨\n",
    "\n",
    " âš  *TOUGHEST DAY:* April 17, your intake was *51% (49% missing)*. It needs to be higher, we have to address this. ğŸ¤¨\n",
    " ğŸ“ˆ *PROGRESS:* The intake for most off-plan day looked better before (now it's 14% worse). ğŸ˜•''', 'compare', 'fat'),\n",
    "    ('''âœ… *TREND:* you should get more energy, in fact, you're slightly rising it .\n",
    " You should keep this up. ğŸ˜ƒ\n",
    "\n",
    " ğŸ“ˆ *PROGRESS:* The trend looked better before ğŸ˜•\n",
    "\n",
    " âœ… *CONSISTENCY:* Your data show a stable daily intake, that's great! ğŸ˜ƒ\n",
    " ğŸ“ˆ *PROGRESS*: The consistency is about the same as before ğŸ§''', 'compare', 'energy'),\n",
    "    ('''ğŸ– *PROTEIN* ğŸ–\n",
    "\n",
    " âš  *ON AVERAGE:* You had *70% (30% missing)*. You should increase your consumption, we need to work on this. ğŸ¤”\n",
    " ğŸ“ˆ *PROGRESS:* The average protein intake improved (now it's 19% better). ğŸ˜\n",
    "\n",
    " âš  *TOUGHEST DAY:* sorry, if any of your periods has only one day I can't get this for you ğŸ˜•''', 'compare', 'protein'),\n",
    "    ('''âš  *TREND AND CONSISTENCY:* for this I need at least 3 days for both periods, sorry ğŸ˜•''', 'compare', 'sodium')\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPHRASING_PROMPT = \"Rephrase the following message to the user, keeping any mentioned numbers and dates. Do not introduce new dates. Do not assume unspecified time periods. Do not add extra information. Do not ask questions. Use emojis.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPHRASING_PROMPT = \"Do not include additional information. Use simple language and emojis. Rephrase the following message to the user.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def generate_ollama_output(model, prompt):#, message=None):\n",
    "    # print('input:', message)\n",
    "    print(prompt)\n",
    "\n",
    "    url = 'http://localhost:11434/api/generate'\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        # \"system\": prompt,\n",
    "        \"prompt\": prompt, #message\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.6\n",
    "        },\n",
    "        \"keep_alive\": -1,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    payload_json = json.dumps(payload, ensure_ascii=False)\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    response = requests.post(url, data=payload_json.encode('utf-8'), headers=headers)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        output = json.loads(response.content.decode('utf-8'))['response']\n",
    "        # print('output:', output)\n",
    "        print(output)\n",
    "        print()\n",
    "    else:\n",
    "        print(\"Error in rephrasing request:\", response.status_code, 'response:', response.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def generate_ollama_output(model, prompt, message=None):\n",
    "    print('input:', message)\n",
    "    # print(prompt)\n",
    "\n",
    "    url = 'http://localhost:11434/api/generate'\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"system\": prompt,\n",
    "        \"prompt\": message,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.6\n",
    "        },\n",
    "        \"keep_alive\": -1,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    payload_json = json.dumps(payload, ensure_ascii=False)\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    response = requests.post(url, data=payload_json.encode('utf-8'), headers=headers)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        output = json.loads(response.content.decode('utf-8'))['response']\n",
    "        # print('output:', output)\n",
    "        print(output)\n",
    "        print()\n",
    "    else:\n",
    "        print(\"Error in rephrasing request:\", response.status_code, 'response:', response.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = {\n",
    "        'ask_feedback': 'You are asking for feedback on the supportive texts you provided the user with. ',\n",
    "        'check_diary': \"You are checking if the user made an error while filling in their food diary yesterday. Tell the user exactly what you noticed. \",\n",
    "        'compare': 'The user requested comparative insights into their {} intake between two specified periods. Keep all information including all percentages of daily goal. Do not greet the user or prompt a response. ',\n",
    "        'compare_average': \"The user requested comparative insights into their average {} intake and toughest day between two specified periods. Specified periods must be longer than one day to calculate toughest day. Keep all information including all percentages of daily goal. Do not greet the user or prompt a response. \",\n",
    "        'compare_trend': 'The user requested comparative insights into the trends and consistency of their {} intake between two specified periods. This can only be calculated if they specify periods both longer than 3 days. Keep all information including all percentages of daily goal. Do not greet the user or prompt a response. ',\n",
    "        'compare_food': 'The user requested comparative insights into the food items that contributed to their {} intake between two specified periods. Keep all information including all percentages of daily goal. Do not greet the user or prompt a response. ',\n",
    "        'compare_no_dates': 'The user requested comparative insights into their food diary but did not give dates. Do not greet the user. ',\n",
    "        'compare_one_date': 'The user requested comparative insights into their food diary but only gave one date. Do not greet the user. ',\n",
    "        'compare_many_dates': 'The user requested comparative insights into their food diary but gave too many dates. Do not greet the user. ',\n",
    "        'counselling': 'You are asking whether the user needs helps with their diet. ',\n",
    "        'retry_counselling': \"You are asking the user whether they want to try explaining their diet issue again with different words. \",\n",
    "        'empty': \"The user requested insights into their food diary for a time period with no data. \",\n",
    "        'empty_message_stack': 'The user has chosen to end the flow of information and buttons. ',\n",
    "        'filter_more_info_button': 'The user is offered button options below for different types of advanced insights of their food diary. Keep the heading. Do not assume the options. ',\n",
    "        'holes_inside_warn': \"The user's food diary has empty days in the specified period, so insights will be calculated without the empty days. Mention any removed dates but do not assume the time period. \",\n",
    "        'holes_surrounding_warn': \"The user's food diary has empty days in the specified period, so insights will be calculated without the empty days. Mention any removed dates but do not assume the time period. Do not ask questions. \",\n",
    "        'invalid_button': 'The user has clicked on a previous button for more advanced insights that is now outdated. You cannot retrieve this information. Do not apologise. ',\n",
    "        'more_info_denied': \"The user's food diary has estimated days that were empty in the specified period, so insights cannot be calculated. \",\n",
    "        'most_data_missing': \"The user's food diary has too many empty days in the specified period, so insights cannot be calculated. Do not ask questions. \",\n",
    "        'no_dates': 'The user requested insights of their food diary but did not specify dates in the correct format. Do not include greetings. ',\n",
    "        'no_dates_default': 'The user requested insights into their food diary but did not specify dates in the correct format. Do not include greetings. ',\n",
    "        'no_multiple_times': 'The user either mentioned more than one time period for insights into their food diary, or more than two time periods for a comparison. Use the same examples. ',\n",
    "        # 'partial_typo': '',\n",
    "        'query_complexity_excess': 'The user requested insights into their food diary over a specified period longer than the maximum of 5 months. ',\n",
    "        'update': 'The user requested insights into their {} intake over a specified period. Keep all information including all percentages of daily goal. Do not greet the user or prompt a response. ',\n",
    "        'update_average': \"The user requested insights into their average {} intake and toughest day over a specified period. The specified period must be longer than one day to calculate toughest day. Keep all information including all percentages of daily goal. Do not greet the user or prompt a response. \",\n",
    "        'update_trend': 'The user requested insights into the trends and consistency of their {} intake over a specified period. This can only be calculated if they specify a period longer than 3 days. Keep all information including all percentages of daily goal. Do not greet the user or prompt a response. ',\n",
    "        'update_food': 'The user requested insights into the food items that contributed to their {} intake over a specified period. Keep all information including all percentages of daily goal. Do not greet the user or prompt a response. ',\n",
    "        'wait': 'The user requested insights into their food diary for the specified period. Keep all mentioned dates. ',\n",
    "        'wait_more': 'The user requested advanced insights into their food diary. ',\n",
    "        'weird_comparison': 'The user requested comparative insights into their food diary across two time periods that overlap, are non-consecutive or are different in length. Do not ask questions. ',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_instruction(prompt, message):\n",
    "    return f\"\"\"{prompt}\n",
    "\n",
    "### Message:\n",
    "{message}\n",
    "\n",
    "### Rephrased message:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for message, intent, nutrient in messages:\n",
    "    if intent==False:\n",
    "        print(message)\n",
    "        continue\n",
    "    generate_ollama_output('llama3', format_instruction(contexts[intent].format(nutrient)+REPHRASING_PROMPT, message))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for message, intent, nutrient in messages:\n",
    "    \n",
    "    if 'AVERAGE' in message:\n",
    "        intent += '_average'\n",
    "    elif 'TREND' in message:\n",
    "        intent += '_trend'\n",
    "    elif 'FOOD' in message:\n",
    "        intent += '_food'\n",
    "        \n",
    "    if intent==False:\n",
    "        print(message)\n",
    "        continue\n",
    "    generate_ollama_output('llama3', format_instruction(contexts[intent].format(nutrient)+REPHRASING_PROMPT, message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsloth Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"unsloth/llama-3-8b-bnb-4bit\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"unsloth/llama-3-8b-bnb-4bit\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_output(messages, model, tokenizer) # 10:40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in messages:\n",
    "    print('input:', message)\n",
    "    input_text = '<start_of_turn>user ' + REPHRASING_PROMPT + message  + '<end_of_turn>\\n<start_of_turn>model\\nResponse:\\n\\n'\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    output = model.generate(**input_ids, max_new_tokens=250, do_sample=True)\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    print('output:', decoded[len(input_text)-43:])\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistral Instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [01:03<00:00, 21.24s/it]\n",
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: I'm checking your data: \n",
      " \n",
      " - from Apr 27 2024 \n",
      " \n",
      " and getting the insights... ğŸ”\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Great news! ğŸ˜ƒ I'm currently analyzing your data from ğŸ“… Apr 27, 2024. ğŸ” Stay tuned for the insights!\n",
      "\n",
      "input: I'm checking your data: \n",
      " \n",
      " - from Apr 22 2024 to Apr 28 2024 \n",
      " \n",
      " and getting the insights... ğŸ”\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Great news! ğŸ¤© I'm currently analyzing your data:\n",
      "\n",
      " - From ğŸ—“ï¸ Apr 22, 2024 to ğŸ—“ï¸ Apr 28, 2024 \n",
      "\n",
      " Stay tuned for the fascinating insights! ğŸ’¡ğŸ”®\n",
      "\n",
      "input: I'm analysing your data: \n",
      " \n",
      " - from Mar 01 2024 to Mar 31 2024 \n",
      " - and from Apr 01 2024 to Apr 30 2024 \n",
      " \n",
      " and checking what changed... ğŸ”\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Great news! ğŸ¤© I'm currently examining your data:\n",
      "\n",
      " - from Mar 1, 2024 to Mar 31, 2024 ğŸ“…\n",
      " - and from Apr 1, 2024 to Apr 30, 2024 ğŸ“…\n",
      "\n",
      "To see what has been altered. ğŸ”\n",
      "\n",
      "input: Your diary looks empty for this period ğŸ¤”\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: è§‰å¾—è¿™æ®µæ—¶é—´ä½ çš„æ—¥ç¨‹ç©ºç©ºå¦‚ä¹ŸğŸ“…ğŸ“…\n",
      "\n",
      "input: come back when you put some data in your diary â˜ºï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Great emoji ğŸ˜ƒ! Return when you've added some info to your calendar ğŸ“….\n",
      "\n",
      "input: Ok, let me analyse your data some more... ğŸ”\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Great, giving your data some extra thought and examination ğŸ’­ğŸ”\n",
      "\n",
      "input: Okay, will be back soon with more info... ğŸ”\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Great, I'll be back soon with more details! ğŸ”ğŸ”\n",
      "\n",
      "input: (Advanced analysis requires time, I'll be back when I'm done...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Ğ¼Ğ¸ ğŸ’»ğŸ”¬ Analyzing deeply, ğŸ•’ will be back soon! ğŸ•™\n",
      "\n",
      "input: (This may take some time, I'll send you a message when it's done...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Great news! ğŸ¤© I'm working on it right now ğŸ”§. I'll be sure to let you know as soon as it's ready ğŸ•’. Stay tuned! ğŸ‘€\n",
      "\n",
      "input: âš  WARNING:  you're comparing two periods with different lenghts. The comparison might be unsafe.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Ã®treWarnings!âš ï¸\n",
      "You're attempting to compare periods of unequal lengths.\n",
      "ğŸ›‘ Proceed with caution. ğŸ’¡\n",
      "\n",
      "input: Some days at the beginning and/or end are missing. ğŸ§ \n",
      " \n",
      " I removed these for you: \n",
      " - Mar 01 - Mar 05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: ğŸ‘‰ Some parts at the start and/or finish are blank. ğŸ˜•\n",
      "\n",
      "I've taken out these sections:\n",
      "- Mar 01 - Mar 05 ğŸ“…\n",
      "\n",
      "input: âš  FOOD: In the chart below you can see how different foods contributes to your intake:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Ñ‰Ğµâ¶ Food Chart: A peek into your consumption of various foods:\n",
      "\n",
      "[ğŸ¥— salad, ğŸ fruit, ğŸ” burger, ğŸ² pasta, ğŸœ rice]\n",
      "\n",
      "ğŸ‘‰ Each emoji represents a specific food from your chart. Stay tuned for more insights! ğŸ”\n",
      "\n",
      "input: âš  TREND: you should get more carbohydrates, but you're slightly decreasing it .\n",
      " It would be better to revert this. ğŸ§ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Ğ¼Ğ¼Ğ¸ğŸ˜• You've been consuming slightly fewer carbohydrates than recommended. ğŸ“‰ It might be a good idea to increase your intake again. ğŸœ #Carbs #HealthyEating #NutritionGoals\n",
      "\n",
      "input: âš  CONSISTENCY: Your daily intake seems pretty variable: try to eat similar amounts every day. ğŸ§\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Ğ¼Ğ¸Ğ¼Ğ¸ĞºÑ€ÑÑ‰Ğ¸Ğµ Ğ³Ğ»Ğ°Ğ·Ğ°: Your daily food consumption appears quite inconsistent: aim for a more regular intake. ğŸ¥—ğŸ”ğŸœğŸ•â˜¹ï¸ (Emojis representing healthy food, fast food, sushi, and pizza to illustrate varying food choices)\n",
      "\n",
      "input: âœ… TREND: you should get more sodium, in fact you're lightly increasing it .\n",
      " This is the right way to go. â˜ºï¸ \n",
      " \n",
      " âš  CONSISTENCY: I see high variability in your daily intake: you should try to avoid changing it so often ğŸ§\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: >:regional_indicator_checkered_flag: YOUR TREND: Consider adding more sodium to your diet. ğŸ‘ğŸ½\n",
      ">:grinning_face_with_smiling_eyes: IT'S THE WAY TO GO. â˜ºï¸\n",
      "\n",
      ">:warning: YOUR CONSISTENCY: I've noticed significant fluctuations in your daily sodium intake. ğŸ§\n",
      ">:confused: TRY TO KEEP IT MORE CONSISTENT. ğŸ”\n",
      "\n",
      "input: âš  TREND: you should keep your actual energy intake, instead you're slightly decreasing it .\n",
      " This is ok for now but better stabilise it to preserve this result ğŸ¤” \n",
      " ğŸ“ˆ PROGRESS: The trend is about the same as before ğŸ¤” \n",
      " \n",
      " âœ… CONSISTENCY: Your daily intake looks regular, good job! ğŸ˜ \n",
      " ğŸ“ˆ PROGRESS: The consistency didn't really change ğŸ¤”\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¸ĞºĞ°: Ğ¢Ñ€ĞµĞ½Ğ´: Ğ²Ğ°ÑˆĞ° Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±Ğ½Ğ¾ÑÑ‚ÑŒ Ğ² ÑĞ½ĞµÑ€Ğ³Ğ¸Ğ¸ Ğ½ĞµĞ¼Ğ½Ğ¾Ğ³Ğ¾ ÑƒĞ¼ĞµĞ½ÑŒÑˆĞ°ĞµÑ‚ÑÑ, Ğ° Ğ½Ğµ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ÑÑ.\n",
      " Ğ­Ñ‚Ğ¾ Ğ² Ğ¿Ğ¾Ñ€ÑĞ´ĞºĞµ Ğ´ĞµĞ» Ğ² Ğ½Ğ°ÑÑ‚Ğ¾ÑÑ‰ĞµĞµ Ğ²Ñ€ĞµĞ¼Ñ, Ğ½Ğ¾ Ğ»ÑƒÑ‡ÑˆĞµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ ÑÑ‚Ğ¾ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ¶ĞµĞ½Ğ¸Ğµ ğŸ¤” \n",
      " ğŸ“ˆ ĞŸÑ€Ğ¾Ğ³Ñ€ĞµÑÑ: Ğ¢Ñ€ĞµĞ½Ğ´ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾ Ñ‚Ğ°ĞºĞ¾Ğ¹ Ğ¶Ğµ, ĞºĞ°Ğº Ñ€Ğ°Ğ½ÑŒÑˆĞµ ğŸ¤”\n",
      "\n",
      " âœ… ĞŸĞ¾ÑÑ‚Ğ¾ÑĞ½ÑÑ‚Ğ²Ğ¾: Ğ’Ğ°ÑˆĞ° ĞµĞ¶ĞµĞ´Ğ½ĞµĞ²Ğ½Ğ°Ñ Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±Ğ½Ğ¾ÑÑ‚ÑŒ Ğ²Ñ‹Ğ³Ğ»ÑĞ´Ğ¸Ñ‚ Ñ€ĞµĞ³ÑƒĞ»ÑÑ€Ğ½Ğ¾Ğ¹, Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾ ÑĞ´ĞµĞ»Ğ°Ğ½Ğ¾! ğŸ˜ \n",
      " ğŸ“ˆ ĞŸÑ€Ğ¾Ğ³Ñ€ĞµÑÑ: ĞŸĞ¾ÑÑ‚Ğ¾ÑĞ½ÑÑ‚Ğ²Ğ¾ Ğ½Ğµ Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ğ»Ğ¾ÑÑŒ Ğ½Ğ°Ğ¼Ğ½Ğ¾Ğ³Ğ¾ ğŸ¤”\n",
      "\n",
      "input: ğŸ– PROTEIN ğŸ– \n",
      " \n",
      " âš  ON AVERAGE: You had 83% (17% deficit). It should be more, we'll have to work on it. ğŸ§\n",
      " \n",
      " \n",
      " âš  TOUGHEST DAY: April 28, your intake was 52% (48% missing). It's not enough, we have to address this. ğŸ§\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: 2. ğŸ” **Low Protein Intake** ğŸ” \n",
      "\n",
      "ğŸ”¨ **Average:** ğŸ“Š You consumed 83% of your daily protein requirement, falling short by 17%. Let's improve it! ğŸ§\n",
      "\n",
      "ğŸš¨ **April 28:** ğŸ“… Your protein intake was only 52%, meaning you missed the mark by 48%. Let's focus on increasing your intake that day! ğŸ§\n",
      "\n",
      "input: ğŸ¬ SUGAR ğŸ¬ \n",
      " \n",
      " âš  ON AVERAGE: You got 55% (45% missing). You need to increase it, we have to address this. ğŸ¤”\n",
      " \n",
      " \n",
      " âš  TOUGHEST DAY: April 26, your intake was 32% (68% missing). It's not enough, we have to address this. ğŸ¤”\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Ñ‰ÂŸÂÂï¸ SWEETS ALERT ğŸ¬ -----\n",
      "\n",
      "â—ï¸ AVERAGE: You've missed 45% of your intake ğŸ˜•, let's work on improving it! ğŸ’¡\n",
      "\n",
      "â—ï¸ TOUGHEST DAY: â˜¹ï¸ April 26, you only consumed 32% ğŸ™ˆ, we need to boost that! ğŸ’ªğŸ¼\n",
      "\n",
      "input: ğŸ”¥ ENERGY ğŸ”¥ \n",
      " \n",
      " âœ… ON AVERAGE: I see a good balance in your energy intake. Well done! ğŸ˜ƒ \n",
      " ğŸ“ˆ PROGRESS: The average energy intake is about the same as before ğŸ§ \n",
      " \n",
      " âš  TOUGHEST DAY: April 17, your intake was 51% (49% missing). It's not enough, we have to address this. ğŸ§\n",
      " ğŸ“ˆ PROGRESS: The intake for most off-plan day is about the same as before ğŸ§\n",
      "output: Great job keeping your energy intake in check ğŸ”¥\n",
      "\n",
      "âœ… AVERAGE: You're maintaining a good balance on average ğŸ˜ƒ\n",
      "ğŸ“ˆ PROGRESS: Your average energy intake remains similar to before ğŸ§\n",
      "\n",
      "âš ï¸ WARNING: On April 17, your energy intake was only 51%, which is 49% less than required ğŸ§\n",
      "ğŸ“ˆ PROGRESS: The energy intake on your most off-plan day remains similar to before ğŸ§\n",
      "\n",
      "ğŸ’¡ SUGGESTION: Let's work together to improve your intake on challenging days ğŸ’ªğŸ¼ğŸ’¡\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for message in messages: # 9:50\n",
    "    print('input:', message)\n",
    "    context = [\n",
    "        {\"role\": \"user\", \"content\": REPHRASING_PROMPT + '\\n' + message},\n",
    "        {\"role\": \"assistant\", \"content\": \"Response:\\n\"},\n",
    "    ]\n",
    "\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        context,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=256,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "    response = outputs[0][input_ids.shape[-1]:]\n",
    "    print('output:', tokenizer.decode(response, skip_special_tokens=True))\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-bit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:12<00:00,  4.07s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    quantization_config=bnb_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: I'm checking your data: \n",
      " \n",
      " - from Apr 27 2024 \n",
      " \n",
      " and getting the insights... ğŸ”\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: great! ğŸŒŸ I'm currently analyzing your data from: \n",
      "- April 27, 2024 ğŸ“…\n",
      "\n",
      "Insights are on the way! ğŸ’¡ğŸ”¬\n",
      "\n",
      "input: I'm checking your data: \n",
      " \n",
      " - from Apr 22 2024 to Apr 28 2024 \n",
      " \n",
      " and getting the insights... ğŸ”\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Great news! ğŸ¤© I'm currently analyzing your data:\n",
      "\n",
      "- From Apr 22, 2024 to Apr 28, 2024 ğŸ“…\n",
      "\n",
      "Give me a moment as I uncover the insights... ğŸ”ğŸ’¡\n",
      "\n",
      "input: I'm analysing your data: \n",
      " \n",
      " - from Mar 01 2024 to Mar 31 2024 \n",
      " - and from Apr 01 2024 to Apr 30 2024 \n",
      " \n",
      " and checking what changed... ğŸ”\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Great news! ğŸŒŸ I'm currently examining your data:\n",
      "\n",
      " - From Mar 01, 2024 to Mar 31, 2024, and\n",
      " - From Apr 01, 2024 to Apr 30, 2024. ğŸ“…\n",
      "\n",
      " I'm putting on my detective hat and digging deep to find any changes that may have occurred during these timeframes. ğŸ”ğŸ•µï¸â€â™€ï¸ Stay tuned! ğŸ”œ\n",
      "\n",
      "input: Your diary looks empty for this period ğŸ¤”\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: great ğŸ“…, it seems your calendar is open for this time! ğŸ˜Š\n",
      "\n",
      "input: come back when you put some data in your diary â˜ºï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Great! ğŸ“… Come back when you've added some data to your diary. â˜ºï¸\n",
      "\n",
      "input: Ok, let me analyse your data some more... ğŸ”\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Great, giving your data some extra thought... ğŸ’­ğŸ”\n",
      "\n",
      "input: Okay, will be back soon with more info... ğŸ”\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Great, I'll be back with new details soon ğŸ”.\n",
      "\n",
      "input: (Advanced analysis requires time, I'll be back when I'm done...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Ğ¼Ğ¸ ğŸ”¬ Analyzing data... ğŸ•’ It may take some time. I'll be back with results. ğŸ“Š Stay tuned! ğŸ”œ\n",
      "\n",
      "input: (This may take some time, I'll send you a message when it's done...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Ğ¼Ğ¸Ğ»Ğ³Ñ€Ğ°Ğ´â³: I'm working on it, ğŸ”„ will keep you posted! ğŸ“£\n",
      "\n",
      "input: âš  WARNING:  you're comparing two periods with different lenghts. The comparison might be unsafe.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Great ğŸŒŸ mind checking something for me?\n",
      "âš ï¸ï¸: Attention!\n",
      "You're comparing two time frames of different lengths.\n",
      "ğŸš« It might not be safe to do so. ğŸš«\n",
      "Please ensure both periods have the same length before making comparisons. ğŸ˜ŠğŸ˜Š\n",
      "\n",
      "input: Some days at the beginning and/or end are missing. ğŸ§ \n",
      " \n",
      " I removed these for you: \n",
      " - Mar 01 - Mar 05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: great ğŸŒŸ, here's an update:\n",
      "\n",
      "I've taken out these specific days for you: ğŸ“…\n",
      "- Mar 01 - Mar 05 ğŸ”„\n",
      "\n",
      "input: âš  FOOD: In the chart below you can see how different foods contributes to your intake:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Great ğŸ“Š here's a peek at how various foods affect your daily consumption:\n",
      "![Chart Emoji](https://emojis.slack-edge.com/TQFUS/food_chart_macro.png)\n",
      "\n",
      "input: âš  TREND: you should get more carbohydrates, but you're slightly decreasing it .\n",
      " It would be better to revert this. ğŸ§ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Ğ¼Ğ¸ğŸ‘‰ You've been decreasing your carbohydrate intake, but it would be better to increase it instead. ğŸ¤¯\n",
      "\n",
      "input: âš  CONSISTENCY: Your daily intake seems pretty variable: try to eat similar amounts every day. ğŸ§\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Ğ¼Ğ¸Ñ€ÑŠ ÑĞ¼oji: ğŸ˜• Your daily food intake shows some variation: strive for more consistency. ğŸ“Š\n",
      "\n",
      "input: âœ… TREND: you should get more sodium, in fact you're lightly increasing it .\n",
      " This is the right way to go. â˜ºï¸ \n",
      " \n",
      " âš  CONSISTENCY: I see high variability in your daily intake: you should try to avoid changing it so often ğŸ§\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Ğ¼Ğ¸ ğŸ“ˆ You're on an upward trend with your sodium intake! Keep it up, you're on the right track. â˜ºï¸\n",
      "\n",
      "ğŸ” However, be mindful of the inconsistency in your daily sodium intake. Try to maintain some regularity. ğŸ§\n",
      "\n",
      "input: âš  TREND: you should keep your actual energy intake, instead you're slightly decreasing it .\n",
      " This is ok for now but better stabilise it to preserve this result ğŸ¤” \n",
      " ğŸ“ˆ PROGRESS: The trend is about the same as before ğŸ¤” \n",
      " \n",
      " âœ… CONSISTENCY: Your daily intake looks regular, good job! ğŸ˜ \n",
      " ğŸ“ˆ PROGRESS: The consistency didn't really change ğŸ¤”\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Ğ¼Ğ¸ âš ï¸ You're currently consuming less energy than before, ğŸ“‰ but try to maintain your intake for consistent results, ğŸ”„\n",
      "ğŸ‘‰ Your daily energy consumption remains consistent, keep up the good work, ğŸ‘ğŸ½ ğŸ’¡\n",
      "ğŸ“ˆ Progress: The trend and consistency of your energy intake remain about the same, ğŸ¤” ğŸ“ˆ\n",
      "\n",
      "input: ğŸ– PROTEIN ğŸ– \n",
      " \n",
      " âš  ON AVERAGE: You had 83% (17% deficit). It should be more, we'll have to work on it. ğŸ§\n",
      " \n",
      " \n",
      " âš  TOUGHEST DAY: April 28, your intake was 52% (48% missing). It's not enough, we have to address this. ğŸ§\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹Ğ¹\\_Ğ±ÑƒÑ‚ĞµÑ€Ğ±Ñ€Ğ¾Ğ´ ğŸ” \\ud83c\\udf0f PROTEIN \\ud83c\\udf0f âš ï¸\n",
      "\n",
      "\\ud83d\\ude2e You had 83% ğŸ“Š (17% deficit) \\ud83d\\ude2e. Needs improvement! ğŸ§\n",
      "\n",
      "\\ud83d\\ude2e April 28: 52% ğŸ“Š (48% missing) \\ud83d\\ude2e. We need to work on this day. ğŸ§\n",
      "\n",
      "input: ğŸ¬ SUGAR ğŸ¬ \n",
      " \n",
      " âš  ON AVERAGE: You got 55% (45% missing). You need to increase it, we have to address this. ğŸ¤”\n",
      " \n",
      " \n",
      " âš  TOUGHEST DAY: April 26, your intake was 32% (68% missing). It's not enough, we have to address this. ğŸ¤”\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Ğ¼Ğ¸Ñ€Ğ¾Ğ³Ğ»Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ: ğŸ¬ SUGAR ğŸ¬\n",
      "\n",
      "â—ï¸ ĞĞ’Ğ“ĞĞ Ğ”Ğ˜Ğ¡Ğ¥Ğ˜Ğ”: Ğ¡Ğ¾ÑÑ‚Ğ°Ğ²Ğ¸Ğ» 55% (45% Ğ½ĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾). ĞÑƒĞ¶Ğ½Ğ¾ ÑƒĞ²ĞµĞ»Ğ¸Ñ‡Ğ¸Ñ‚ÑŒ, Ğ½ÑƒĞ¶Ğ½Ğ¾ Ñ€ĞµÑˆĞ°Ñ‚ÑŒ ÑÑ‚Ğ¾. ğŸ¤”\n",
      "\n",
      "â—ï¸ Ğ¡ĞĞœĞ«Ğ™ Ğ¢Ğ Ğ•Ğ‘ĞĞ’ĞĞ¢Ğ•Ğ›Ğ¬ĞĞ«Ğ™ Ğ”Ğ•ĞĞ¬: Ğš 26 Ğ°Ğ¿Ñ€. Ğ’Ğ°Ñˆ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±Ğ»ĞµĞ½Ğ¸Ñ ÑĞ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞ» 32% (68% Ğ½ĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾). ĞĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾, Ğ½ÑƒĞ¶Ğ½Ğ¾ Ñ€ĞµÑˆĞ°Ñ‚ÑŒ ÑÑ‚Ğ¾. ğŸ¤”\n",
      "\n",
      "Translation:\n",
      "Sweet emojis: ğŸ¬ SUGAR ğŸ¬\n",
      "\n",
      "âš ï¸ AVERAGE: You had 55%, which is 45% less. You need to increase it, we have to address this. ğŸ¤”\n",
      "\n",
      "âš ï¸ TOUGHEST DAY: On April 26, your intake was 32%, which is 68% less. It's not enough, we have to address\n",
      "\n",
      "input: ğŸ”¥ ENERGY ğŸ”¥ \n",
      " \n",
      " âœ… ON AVERAGE: I see a good balance in your energy intake. Well done! ğŸ˜ƒ \n",
      " ğŸ“ˆ PROGRESS: The average energy intake is about the same as before ğŸ§ \n",
      " \n",
      " âš  TOUGHEST DAY: April 17, your intake was 51% (49% missing). It's not enough, we have to address this. ğŸ§\n",
      " ğŸ“ˆ PROGRESS: The intake for most off-plan day is about the same as before ğŸ§\n",
      "output: Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ­Ğ½ĞµÑ€Ğ³Ğ¸Ñ/////////\n",
      "\n",
      "âœ… Ğ‘ĞĞ›ĞĞĞ¡: Ğ¢Ğ²Ğ¾Ğ¹ Ğ±Ğ°Ğ»Ğ°Ğ½Ñ ÑĞ½ĞµÑ€Ğ³Ğ¸Ğ¸ Ğ² ÑÑ€ĞµĞ´Ğ½ĞµĞ¼ Ğ²Ğ¿ĞµÑ‡Ğ°Ñ‚Ğ»ÑĞµÑ‚! ğŸ˜Š\n",
      "ğŸ“ˆ ĞŸĞ ĞĞ“Ğ Ğ•Ğ¡Ğ¡: Ğ¡Ñ€ĞµĞ´Ğ½ĞµĞµ Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ½ĞµÑ€Ğ³Ğ¸Ğ¸ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾ Ñ‚Ğ°ĞºĞ¾Ğµ Ğ¶Ğµ, ĞºĞ°Ğº Ñ€Ğ°Ğ½ÑŒÑˆĞµ ğŸ¤”\n",
      "\n",
      "âš  Ğ¥Ğ£Ğ”Ğ¨Ğ˜Ğ™ Ğ”Ğ•ĞĞ¬: 17 Ğ°Ğ¿Ñ€ĞµĞ»Ñ - Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞ»Ğ¾ 51% (Ğ¾ÑÑ‚Ğ°Ğ»Ğ¾ÑÑŒ 49%). ĞÑƒĞ¶Ğ½Ğ¾ Ñ€ĞµÑˆĞ°Ñ‚ÑŒ ÑÑ‚Ñƒ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ. ğŸ§\n",
      "ğŸ“ˆ ĞŸĞ ĞĞ“Ğ Ğ•Ğ¡Ğ¡: ĞŸĞ¾Ñ‚Ñ€ĞµĞ±Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ½ĞµÑ€Ğ³Ğ¸Ğ¸ Ğ½Ğ° Ğ´Ğ½ÑÑ…, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ½Ğµ ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ»Ğ¸ Ğ¿Ğ»Ğ°Ğ½Ñƒ, Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾ Ñ‚Ğ°ĞºĞ¾Ğµ Ğ¶Ğµ, ĞºĞ°Ğº Ñ€Ğ°Ğ½ÑŒÑˆĞµ ğŸ§\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for message in messages: # 3:30\n",
    "    print('input:', message)\n",
    "    context = [\n",
    "        {\"role\": \"user\", \"content\": REPHRASING_PROMPT + '\\n' + message},\n",
    "        {\"role\": \"assistant\", \"content\": \"Response:\\n\"},\n",
    "    ]\n",
    "\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        context,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=256,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "    response = outputs[0][input_ids.shape[-1]:]\n",
    "    print('output:', tokenizer.decode(response, skip_special_tokens=True))\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPHRASING_PROMPT = \"Without assuming any dates but keeping numbers, rephrase the following message in a more natural way.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:50<00:00, 12.65s/it]\n",
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-7b-it\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"google/gemma-7b-it\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: I'm checking your data: \n",
      " \n",
      " - from Apr 27 2024 \n",
      " \n",
      " and getting the insights... ğŸ”\n",
      "output: Sure, here is the rephrased message:\n",
      "\n",
      "\"I'm checking your data from **Apr 27 2024** and getting the insights... ğŸ”\"\n",
      "\n",
      "input: I'm checking your data: \n",
      " \n",
      " - from Apr 22 2024 to Apr 28 2024 \n",
      " \n",
      " and getting the insights... ğŸ”\n",
      "output: Sure, here is the rephrased message with the dates preserved:\n",
      "\n",
      "Hey, I'm checking your data from **Apr 22 2024** to **Apr 28 2024** and getting the insights... ğŸ”\n",
      "\n",
      "input: I'm analysing your data: \n",
      " \n",
      " - from Mar 01 2024 to Mar 31 2024 \n",
      " - and from Apr 01 2024 to Apr 30 2024 \n",
      " \n",
      " and checking what changed... ğŸ”\n",
      "output: Sure, here is the rephrased message with the mentioned dates preserved:\n",
      "\n",
      "\"I'm analyzing your data from Mar 01 2024 to Mar 31 2024 and from Apr 01 2024 to Apr 30 2024. I'm checking what changed... ğŸ”\"\n",
      "\n",
      "input: Your diary looks empty for this period ğŸ¤”\n",
      "output: Sure, here's the rephrased message for the user:\n",
      "\n",
      "Your diary is currently empty for this period ğŸ¤”.\n",
      "\n",
      "input: come back when you put some data in your diary â˜ºï¸\n",
      "output: Sure, here is the rephrased message with the original dates:\n",
      "\n",
      "\"Come back when you've put some data in your diary, and I'll be waiting for you! ğŸ˜Š\"\n",
      "\n",
      "input: Ok, let me analyse your data some more... ğŸ”\n",
      "output: Sure, here is the rephrased message:\n",
      "\n",
      "\"I'm still analyzing your data, ğŸ”. I'll get back to you soon with my findings.\"\n",
      "\n",
      "input: Okay, will be back soon with more info... ğŸ”\n",
      "output: Sure, here's the rephrased message:\n",
      "\n",
      "\"Okay, I'll be back soon with more info... ğŸ” See you soon!\"\n",
      "\n",
      "input: (Advanced analysis requires time, I'll be back when I'm done...)\n",
      "output: Sure, here is the rephrased message:\n",
      "\n",
      "\"Advanced analysis takes time. I'm currently working on it and I'll be back when I'm finished. â³\"\n",
      "\n",
      "input: (This may take some time, I'll send you a message when it's done...)\n",
      "output: Sure, here's the rephrased message:\n",
      "\n",
      "\"This may take a while, I'll let you know when it's finished. â³\"\n",
      "\n",
      "input: âš  WARNING:  you're comparing two periods with different lenghts. The comparison might be unsafe.\n",
      "output: Sure, here is the rephrased message with the original dates:\n",
      "\n",
      "âš ï¸ Warning: You're comparing two periods with different lengths. The comparison might be unsafe. ğŸ¤”\n",
      "\n",
      "input: Some days at the beginning and/or end are missing. ğŸ§ \n",
      " \n",
      " I removed these for you: \n",
      " - Mar 01 - Mar 05\n",
      "output: Sure, here's the rephrased message:\n",
      "\n",
      "Some days at the beginning and/or end are missing. ğŸ§\n",
      "\n",
      "I removed:\n",
      "\n",
      "- Mar 01 - Mar 05\n",
      "\n",
      "No other changes were made.\n",
      "\n",
      "input: âš  FOOD: In the chart below you can see how different foods contributes to your intake:\n",
      "output: Sure, here is the rephrased message with the mentioned dates preserved:\n",
      "\n",
      "âš  FOOD: In the chart below, you can see how different foods contribute to your intake on [Date] and [Date].\n",
      "\n",
      "input: âš  TREND: you should get more carbohydrates, but you're slightly decreasing it .\n",
      " It would be better to revert this. ğŸ§ \n",
      "output: Sure, here is the rephrased message:\n",
      "\n",
      "âš  TREND: You should increase your carbohydrates, but you're slightly decreasing it. ğŸ¤” It would be better to revert this trend. ğŸ§\n",
      "\n",
      "input: âš  CONSISTENCY: Your daily intake seems pretty variable: try to eat similar amounts every day. ğŸ§\n",
      "output: Sure, here is the rephrased message:\n",
      "\n",
      "âš  CONSISTENCY: Your daily intake is a bit all over the place lately ğŸ¤”. Try to eat similar amounts every day for a more consistent routine ğŸ½ï¸.\n",
      "\n",
      "input: âœ… TREND: you should get more sodium, in fact you're lightly increasing it .\n",
      " This is the right way to go. â˜ºï¸ \n",
      " \n",
      " âš  CONSISTENCY: I see high variability in your daily intake: you should try to avoid changing it so often ğŸ§\n",
      "output: Sure, here is the rephrased message:\n",
      "\n",
      "âœ… TREND: You should increase your sodium intake, it's going in the right direction! ğŸ‘\n",
      "\n",
      "âš  CONSISTENCY: I see a lot of variability in your daily intake, try to keep it more consistent. ğŸ˜Ÿ\n",
      "\n",
      "input: âš  TREND: you should keep your actual energy intake, instead you're slightly decreasing it .\n",
      " This is ok for now but better stabilise it to preserve this result ğŸ¤” \n",
      " ğŸ“ˆ PROGRESS: The trend is about the same as before ğŸ¤” \n",
      " \n",
      " âœ… CONSISTENCY: Your daily intake looks regular, good job! ğŸ˜ \n",
      " ğŸ“ˆ PROGRESS: The consistency didn't really change ğŸ¤”\n",
      "output: Sure, here is the rephrased message:\n",
      "\n",
      "**Hey, you! ğŸ‘‹**\n",
      "\n",
      "**TREND:** You're slightly decreasing your actual energy intake compared to your previous trend âš . While this is okay for now, it's better to stabilize it to preserve your current results ğŸ¤”.\n",
      "\n",
      "**Consistency:** Your daily intake looks regular, good job! ğŸ˜\n",
      "\n",
      "**Progress:** The trend is about the same as before ğŸ¤” and the consistency didn't really change ğŸ“ˆ. Keep up the good work! ğŸ‰\n",
      "\n",
      "input: ğŸ– PROTEIN ğŸ– \n",
      " \n",
      " âš  ON AVERAGE: You had 83% (17% deficit). It should be more, we'll have to work on it. ğŸ§\n",
      " \n",
      " \n",
      " âš  TOUGHEST DAY: April 28, your intake was 52% (48% missing). It's not enough, we have to address this. ğŸ§\n",
      "output: Sure, here's the rephrased message:\n",
      "\n",
      "ğŸ– PROTEIN ğŸ–\n",
      "\n",
      "âš  ON AVERAGE: You had 83% (17% deficit) protein intake today. We need to increase your intake, we'll have to work on it. ğŸ§\n",
      "\n",
      "âš  TOUGHEST DAY: April 28, your intake was 52% (48% missing). This is not enough, we have to address this. ğŸ§\n",
      "\n",
      "input: ğŸ¬ SUGAR ğŸ¬ \n",
      " \n",
      " âš  ON AVERAGE: You got 55% (45% missing). You need to increase it, we have to address this. ğŸ¤”\n",
      " \n",
      " \n",
      " âš  TOUGHEST DAY: April 26, your intake was 32% (68% missing). It's not enough, we have to address this. ğŸ¤”\n",
      "output: Sure, here's the rephrased message with the mentioned dates:\n",
      "\n",
      "ğŸ¬ Sugar ğŸ¬\n",
      "\n",
      "âš  ON AVERAGE: You've got 55% (45% missing). We need to increase your intake, ASAP. ğŸ¤”\n",
      "\n",
      "âš  TOUGHEST DAY: April 26, your intake was 32% (68% missing). It's not enough, we have to address this. ğŸ¤”\n",
      "\n",
      "input: ğŸ”¥ ENERGY ğŸ”¥ \n",
      " \n",
      " âœ… ON AVERAGE: I see a good balance in your energy intake. Well done! ğŸ˜ƒ \n",
      " ğŸ“ˆ PROGRESS: The average energy intake is about the same as before ğŸ§ \n",
      " \n",
      " âš  TOUGHEST DAY: April 17, your intake was 51% (49% missing). It's not enough, we have to address this. ğŸ§\n",
      " ğŸ“ˆ PROGRESS: The intake for most off-plan day is about the same as before ğŸ§\n",
      "output: Sure, here is the rephrased message to the user, keeping all mentioned dates:\n",
      "\n",
      "ğŸ”¥ ENERGY ğŸ”¥\n",
      "\n",
      "âœ… ON AVERAGE: Your energy intake is well-balanced! ğŸ’ª\n",
      "\n",
      "ğŸ“ˆ PROGRESS: The average energy intake is similar to previous days. ğŸ‘\n",
      "\n",
      "âš  TOUGHEST DAY: On April 17th, your intake was 51% (49% missing). We need to work on this together. ğŸ¤\n",
      "\n",
      "ğŸ“ˆ PROGRESS: The average intake for most off-plan day is similar to previous days. ğŸ‘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for message in messages: # 15:20\n",
    "    print('input:', message)\n",
    "    context = [\n",
    "        {\"role\": \"user\", \"content\": REPHRASING_PROMPT + '\\n' + message},\n",
    "        {\"role\": \"model\", \"content\": \"Response: \"},\n",
    "    ]\n",
    "\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        context,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=256,\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "    response = outputs[0][input_ids.shape[-1]:]\n",
    "    print('output:', tokenizer.decode(response, skip_special_tokens=True))\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-bit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:44<00:00, 11.21s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-7b-it\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"google/gemma-7b-it\",\n",
    "    quantization_config=bnb_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: I'm checking your data: \n",
      " \n",
      " - from Apr 27 2024 \n",
      " \n",
      " and getting the insights... ğŸ”\n",
      "output: Sure, here is the rephrased message:\n",
      "\n",
      "I'm checking your data from **Apr 27 2024** and getting the insights... ğŸ”\n",
      "\n",
      "input: I'm checking your data: \n",
      " \n",
      " - from Apr 22 2024 to Apr 28 2024 \n",
      " \n",
      " and getting the insights... ğŸ”\n",
      "output: Sure, here is the rephrased message:\n",
      "\n",
      "I'm checking your data from **Apr 22 2024** to **Apr 28 2024** and getting the insights... ğŸ”\n",
      "\n",
      "input: I'm analysing your data: \n",
      " \n",
      " - from Mar 01 2024 to Mar 31 2024 \n",
      " - and from Apr 01 2024 to Apr 30 2024 \n",
      " \n",
      " and checking what changed... ğŸ”\n",
      "output: Sure, here's the rephrased message:\n",
      "\n",
      "I'm analyzing your data:\n",
      "\n",
      "- from **Mar 01 2024** to **Mar 31 2024**\n",
      "- and from **Apr 01 2024** to **Apr 30 2024**\n",
      "\n",
      "And checking what changed... ğŸ”\n",
      "\n",
      "input: Your diary looks empty for this period ğŸ¤”\n",
      "output: Sure, here is the rephrased message:\n",
      "\n",
      "Your diary is currently empty for this period. ğŸ¤” Is there anything you'd like to add?\n",
      "\n",
      "input: come back when you put some data in your diary â˜ºï¸\n",
      "output: Sure, here is the rephrased message:\n",
      "\n",
      "Come back when you have put some data in your diary. ğŸ“ğŸ˜Š\n",
      "\n",
      "input: Ok, let me analyse your data some more... ğŸ”\n",
      "output: Sure, here's the rephrased message:\n",
      "\n",
      "\"I'm still analyzing your data... ğŸ” Can I continue with the analysis based on the previously mentioned dates?\"\n",
      "\n",
      "input: Okay, will be back soon with more info... ğŸ”\n",
      "output: Okay, I'll be back soon with more info ğŸ”. See you later!\n",
      "\n",
      "input: (Advanced analysis requires time, I'll be back when I'm done...)\n",
      "output: Sure, here's the rephrased message:\n",
      "\n",
      "\"Advanced analysis takes time, so I'm busy finishing up and will be back when I'm done. â³\"\n",
      "\n",
      "input: (This may take some time, I'll send you a message when it's done...)\n",
      "output: Sure, here is the rephrased message:\n",
      "\n",
      "\"This may take a while, I'll let you know when it's finished. â³\"\n",
      "\n",
      "input: âš  WARNING:  you're comparing two periods with different lenghts. The comparison might be unsafe.\n",
      "output: Sure, here is the rephrased message:\n",
      "\n",
      "âš  WARNING: You're comparing two periods with different lengths. The comparison might be unsafe. âš ï¸\n",
      "\n",
      "input: Some days at the beginning and/or end are missing. ğŸ§ \n",
      " \n",
      " I removed these for you: \n",
      " - Mar 01 - Mar 05\n",
      "output: Sure, here is the rephrased message with the dates preserved:\n",
      "\n",
      "Some days at the beginning and/or end are missing. ğŸ§\n",
      "\n",
      "I removed:\n",
      "\n",
      "- Mar 01 - Mar 05\n",
      "\n",
      "input: âš  FOOD: In the chart below you can see how different foods contributes to your intake:\n",
      "output: Sure, here's the rephrased message with the original dates:\n",
      "\n",
      "âš  FOOD: In the chart below, you can see how different foods contribute to your intake on [Date] and [Date].\n",
      "\n",
      "input: âš  TREND: you should get more carbohydrates, but you're slightly decreasing it .\n",
      " It would be better to revert this. ğŸ§ \n",
      "output: Sure, here is the rephrased message:\n",
      "\n",
      "âš  TREND: You're slightly decreasing your carbs, but should increase them. ğŸ“ˆ It would be better to revert this trend. ğŸ§\n",
      "\n",
      "input: âš  CONSISTENCY: Your daily intake seems pretty variable: try to eat similar amounts every day. ğŸ§\n",
      "output: Sure, here's the rephrased message:\n",
      "\n",
      "âš  CONSISTENCY: Your daily food intake is a bit all over the place lately. ğŸ¤” Can you try to eat similar amounts every day? ğŸ½ï¸\n",
      "\n",
      "input: âœ… TREND: you should get more sodium, in fact you're lightly increasing it .\n",
      " This is the right way to go. â˜ºï¸ \n",
      " \n",
      " âš  CONSISTENCY: I see high variability in your daily intake: you should try to avoid changing it so often ğŸ§\n",
      "output: Sure, here is the rephrased message, keeping the mentioned dates:\n",
      "\n",
      "âœ… TREND: You should increase your sodium intake a bit. It's a good trend ğŸ‘\n",
      "\n",
      "âš  CONSISTENCY: I see a lot of variability in your daily sodium intake. Try to keep it more consistent ğŸ™\n",
      "\n",
      "input: âš  TREND: you should keep your actual energy intake, instead you're slightly decreasing it .\n",
      " This is ok for now but better stabilise it to preserve this result ğŸ¤” \n",
      " ğŸ“ˆ PROGRESS: The trend is about the same as before ğŸ¤” \n",
      " \n",
      " âœ… CONSISTENCY: Your daily intake looks regular, good job! ğŸ˜ \n",
      " ğŸ“ˆ PROGRESS: The consistency didn't really change ğŸ¤”\n",
      "output: Sure, here is the rephrased message with the dates preserved:\n",
      "\n",
      "âš  TREND: You're slightly decreasing your actual energy intake, which is ok for now, but better stabilize it to preserve this result ğŸ¤”.\n",
      "\n",
      "ğŸ“ˆ PROGRESS: The trend is about the same as before ğŸ¤”.\n",
      "\n",
      "âœ… CONSISTENCY: Your daily intake looks regular, good job! ğŸ˜\n",
      "\n",
      "ğŸ“ˆ PROGRESS: The consistency didn't really change ğŸ¤”.\n",
      "\n",
      "input: ğŸ– PROTEIN ğŸ– \n",
      " \n",
      " âš  ON AVERAGE: You had 83% (17% deficit). It should be more, we'll have to work on it. ğŸ§\n",
      " \n",
      " \n",
      " âš  TOUGHEST DAY: April 28, your intake was 52% (48% missing). It's not enough, we have to address this. ğŸ§\n",
      "output: Sure, here's the rephrased message:\n",
      "\n",
      "ğŸ– PROTEIN ğŸ–\n",
      "\n",
      "âš  ON AVERAGE: You had 83% (17% deficit) protein intake today. We need to work on increasing your intake, it should be more. ğŸ§\n",
      "\n",
      "âš  TOUGHEST DAY: April 28, your intake was 52% (48% missing). It's not enough, we have to address this. ğŸ§\n",
      "\n",
      "input: ğŸ¬ SUGAR ğŸ¬ \n",
      " \n",
      " âš  ON AVERAGE: You got 55% (45% missing). You need to increase it, we have to address this. ğŸ¤”\n",
      " \n",
      " \n",
      " âš  TOUGHEST DAY: April 26, your intake was 32% (68% missing). It's not enough, we have to address this. ğŸ¤”\n",
      "output: Sure, here is the rephrased message:\n",
      "\n",
      "ğŸ¬ Sugar ğŸ¬\n",
      "\n",
      "âš  ON AVERAGE: You're missing 55% (45% missing). We need to increase your intake, ASAP. ğŸ¤”\n",
      "\n",
      "âš  TOUGHEST DAY: April 26, your intake was 32% (68% missing). It's not enough, we have to address this. ğŸ¤”\n",
      "\n",
      "input: ğŸ”¥ ENERGY ğŸ”¥ \n",
      " \n",
      " âœ… ON AVERAGE: I see a good balance in your energy intake. Well done! ğŸ˜ƒ \n",
      " ğŸ“ˆ PROGRESS: The average energy intake is about the same as before ğŸ§ \n",
      " \n",
      " âš  TOUGHEST DAY: April 17, your intake was 51% (49% missing). It's not enough, we have to address this. ğŸ§\n",
      " ğŸ“ˆ PROGRESS: The intake for most off-plan day is about the same as before ğŸ§\n",
      "output: Sure, here is the rephrased message:\n",
      "\n",
      "ğŸ”¥ ENERGY ğŸ”¥\n",
      "\n",
      "âœ… ON AVERAGE: You're doing well with your energy intake, it's on average the same as before ğŸ‰\n",
      "\n",
      "ğŸ“ˆ PROGRESS: The average energy intake for most off-plan day is about the same as before ğŸ§\n",
      "\n",
      "âš  TOUGHEST DAY: On April 17th, your intake was 51% (49% missing). We need to address this ASAP to ensure optimal energy levels. ğŸ˜Ÿ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for message in messages: # 2:25\n",
    "    print('input:', message)\n",
    "    context = [\n",
    "        {\"role\": \"user\", \"content\": REPHRASING_PROMPT + '\\n' + message},\n",
    "        {\"role\": \"model\", \"content\": \"Response: \"},\n",
    "    ]\n",
    "\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        context,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=256,\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "    response = outputs[0][input_ids.shape[-1]:]\n",
    "    print('output:', tokenizer.decode(response, skip_special_tokens=True))\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:17<00:00,  8.62s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b-it\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"google/gemma-2b-it\",\n",
    "    device_map=\"auto\",\n",
    "    # torch_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: I'm checking your data: \n",
      " \n",
      " - from Apr 27 2024 \n",
      " \n",
      " and getting the insights... ğŸ”\n",
      "output: Hey there! ğŸ‘‹\n",
      "\n",
      "I'm taking a peek at your data from April 27, 2024. Let me analyze it and give you some insights! ğŸ¤”\n",
      "\n",
      "input: I'm checking your data: \n",
      " \n",
      " - from Apr 22 2024 to Apr 28 2024 \n",
      " \n",
      " and getting the insights... ğŸ”\n",
      "output: Sure, here's the rephrased message:\n",
      "\n",
      "ğŸš¨ Your data is being checked from April 22nd to April 28th, 2024! ğŸš¨\n",
      "\n",
      "Let us know what you find out! ğŸ‘€\n",
      "\n",
      "input: I'm analysing your data: \n",
      " \n",
      " - from Mar 01 2024 to Mar 31 2024 \n",
      " - and from Apr 01 2024 to Apr 30 2024 \n",
      " \n",
      " and checking what changed... ğŸ”\n",
      "output: Sure, here is the rephrased message:\n",
      "\n",
      "ğŸš¨ Data Analysis: ğŸš¨\n",
      "\n",
      "- From Mar 01 to Mar 31, 2024 ğŸ“¢\n",
      "- From Apr 01 to Apr 30, 2024 ğŸ’¥\n",
      "\n",
      "I'm analyzing your data to see what changed! ğŸ¤”\n",
      "\n",
      "input: Your diary looks empty for this period ğŸ¤”\n",
      "output: Your diary looks empty right now ğŸ¥º. ğŸ¤”\n",
      "\n",
      "input: come back when you put some data in your diary â˜ºï¸\n",
      "output: ğŸ¤” Your diary is waiting for some input! ğŸ“ Give it some data, and then come back and check what you've got. ğŸ˜\n",
      "\n",
      "input: Ok, let me analyse your data some more... ğŸ”\n",
      "output: Sure, here is the rephrased message:\n",
      "\n",
      "\"Hey there! I'm taking a peek at your data now. ğŸ” It's like a treasure hunt for insights, but with more details. ğŸ” What's on your mind for me to explore further?\"\n",
      "\n",
      "input: Okay, will be back soon with more info... ğŸ”\n",
      "output: Sure, here's the rephrased message:\n",
      "\n",
      "ğŸš¨ We're back soon with some exciting news! ğŸš¨\n",
      "\n",
      "Stay tuned for more details. ğŸ‘€\n",
      "\n",
      "input: (Advanced analysis requires time, I'll be back when I'm done...)\n",
      "output: Sure, here's the rephrased message:\n",
      "\n",
      "ğŸš¨ Advanced analysis requires time, I'll be back when I'm done! ğŸš¨\n",
      "\n",
      "Let me know when I can assist you further.\n",
      "\n",
      "input: (This may take some time, I'll send you a message when it's done...)\n",
      "output: Sure, here's the rephrased message:\n",
      "\n",
      "ğŸ‘‹ Your message has been sent! ğŸ¤© I'll let you know when it's done. â³\n",
      "\n",
      "#StayTuned\n",
      "\n",
      "input: âš  WARNING:  you're comparing two periods with different lenghts. The comparison might be unsafe.\n",
      "output: âš ï¸ WARNING: Comparing two periods with different lengths could be unsafe. Make sure the periods have the same duration before trying to compare them.\n",
      "\n",
      "input: Some days at the beginning and/or end are missing. ğŸ§ \n",
      " \n",
      " I removed these for you: \n",
      " - Mar 01 - Mar 05\n",
      "output: Some days at the beginning or end are missing. ğŸ¤”\n",
      "\n",
      "I removed these for you:\n",
      "\n",
      "- Mar 01 - Mar 05 ğŸš€\n",
      "\n",
      "input: âš  FOOD: In the chart below you can see how different foods contributes to your intake:\n",
      "output: âš ï¸ Food! ğŸğŸ—ğŸ¥‘\n",
      "\n",
      "Check out this chart and see which foods are giving you the most nutrients ğŸ’ªğŸŒğŸ“! ğŸ˜‹\n",
      "\n",
      "input: âš  TREND: you should get more carbohydrates, but you're slightly decreasing it .\n",
      " It would be better to revert this. ğŸ§ \n",
      "output: âš ï¸ Trend: Reduce your carbohydrate intake slightly. ğŸ¤”\n",
      "\n",
      "It might be better to go back to eating more carbs. ğŸ¤”\n",
      "\n",
      "input: âš  CONSISTENCY: Your daily intake seems pretty variable: try to eat similar amounts every day. ğŸ§\n",
      "output: âš ï¸ Consistency: Your daily intake seems a bit inconsistent lately. Try eating roughly the same amount of food each day to maintain your health. ğŸ¤”\n",
      "\n",
      "input: âœ… TREND: you should get more sodium, in fact you're lightly increasing it .\n",
      " This is the right way to go. â˜ºï¸ \n",
      " \n",
      " âš  CONSISTENCY: I see high variability in your daily intake: you should try to avoid changing it so often ğŸ§\n",
      "output: ğŸ‰ You're on the right track! ğŸ’ª Keep increasing your sodium intake a little bit at a time. ğŸ¥³\n",
      "\n",
      "ğŸ¤” Be mindful of how often you adjust your intake. ğŸ¤” Consistency is key to staying healthy!\n",
      "\n",
      "input: âš  TREND: you should keep your actual energy intake, instead you're slightly decreasing it .\n",
      " This is ok for now but better stabilise it to preserve this result ğŸ¤” \n",
      " ğŸ“ˆ PROGRESS: The trend is about the same as before ğŸ¤” \n",
      " \n",
      " âœ… CONSISTENCY: Your daily intake looks regular, good job! ğŸ˜ \n",
      " ğŸ“ˆ PROGRESS: The consistency didn't really change ğŸ¤”\n",
      "output: âš  Keep your energy intake the same for now, it's okay to slightly decrease it. ğŸ’ª\n",
      "\n",
      "This trend is pretty stable, so keep things consistent to maintain this positive result ğŸ¤©\n",
      "\n",
      "ğŸ“ˆ Progress: The trend is similar to before ğŸ¤”\n",
      "\n",
      "âœ… Consistency: Your daily intake looks good! ğŸ‘\n",
      "\n",
      "ğŸ“ˆ Progress: The consistency stayed the same ğŸ¤”\n",
      "\n",
      "input: ğŸ– PROTEIN ğŸ– \n",
      " \n",
      " âš  ON AVERAGE: You had 83% (17% deficit). It should be more, we'll have to work on it. ğŸ§\n",
      " \n",
      " \n",
      " âš  TOUGHEST DAY: April 28, your intake was 52% (48% missing). It's not enough, we have to address this. ğŸ§\n",
      "output: ğŸ’ª ğŸ’ª ğŸ’ª\n",
      "\n",
      "âš ï¸ Reminder: You're falling behind on your protein intake! ğŸ˜¨\n",
      "\n",
      "ğŸ˜© It's not as high as it should be, at 83%. We need to figure this out together.\n",
      "\n",
      "ğŸ˜© The toughest day this week is April 28th, with a shocking 52% of your intake missing! ğŸ˜­\n",
      "\n",
      "We need to step up our protein game! ğŸ’ª\n",
      "\n",
      "input: ğŸ¬ SUGAR ğŸ¬ \n",
      " \n",
      " âš  ON AVERAGE: You got 55% (45% missing). You need to increase it, we have to address this. ğŸ¤”\n",
      " \n",
      " \n",
      " âš  TOUGHEST DAY: April 26, your intake was 32% (68% missing). It's not enough, we have to address this. ğŸ¤”\n",
      "output: ğŸš¨ SUGAR ğŸ¬\n",
      "\n",
      "âš ï¸ ON AVERAGE: 55% (45% missing)! ğŸ˜© We need to bump it up, it's not enough. ğŸ¤”\n",
      "\n",
      "âš ï¸ TOUGHEST DAY: ğŸš¨ April 26, your intake was 32% (68% missing)! ğŸ˜­ We need to step up our game. ğŸ¤”\n",
      "\n",
      "input: ğŸ”¥ ENERGY ğŸ”¥ \n",
      " \n",
      " âœ… ON AVERAGE: I see a good balance in your energy intake. Well done! ğŸ˜ƒ \n",
      " ğŸ“ˆ PROGRESS: The average energy intake is about the same as before ğŸ§ \n",
      " \n",
      " âš  TOUGHEST DAY: April 17, your intake was 51% (49% missing). It's not enough, we have to address this. ğŸ§\n",
      " ğŸ“ˆ PROGRESS: The intake for most off-plan day is about the same as before ğŸ§\n",
      "output: ğŸ”¥ ğŸ”¥\n",
      "\n",
      "âœ… Energy balance is ğŸ”¥, you're doing great! ğŸ¤©\n",
      "\n",
      "ğŸ“ˆ Average energy intake is about the same as before ğŸ¤”.\n",
      "\n",
      "âš  Toughest day of the week! å››æœˆ 17th, your intake was 51% (49% missing)! ğŸ˜© It's not enough, we need to address this. ğŸ¤”\n",
      "\n",
      "ğŸ“ˆ Most off-plan days have the same energy intake ğŸ¤”.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for message in messages: # ??\n",
    "    print('input:', message)\n",
    "    context = [\n",
    "        {\"role\": \"user\", \"content\": REPHRASING_PROMPT + '\\n' + message},\n",
    "    ]\n",
    "\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        context,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=256,\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "    response = outputs[0][input_ids.shape[-1]:]\n",
    "    print('output:', tokenizer.decode(response, skip_special_tokens=True))\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: I'm checking your data: \n",
      " \n",
      " - from Apr 27 2024 \n",
      " \n",
      " and getting the insights... ğŸ”\n",
      "output: Checking your data from Apr 27th 2024... ğŸ”\n",
      "\n",
      "input: I'm checking your data: \n",
      " \n",
      " - from Apr 22 2024 to Apr 28 2024 \n",
      " \n",
      " and getting the insights... ğŸ”\n",
      "output: Checking data from April 22 to 28 ğŸ—“ï¸ and gathering insights! ğŸ”\n",
      "\n",
      "input: I'm analysing your data: \n",
      " \n",
      " - from Mar 01 2024 to Mar 31 2024 \n",
      " - and from Apr 01 2024 to Apr 30 2024 \n",
      " \n",
      " and checking what changed... ğŸ”\n",
      "output:  analizing your data from Mar 1st to Mar 31st and Apr 1st to Apr 30th ğŸ—“ï¸ to see what's changed! ğŸ”\n",
      "\n",
      "input: Your diary looks empty for this period ğŸ¤”\n",
      "output: Your diary is currently blank for this timeframe ğŸ“šğŸ¤”\n",
      "\n",
      "input: come back when you put some data in your diary â˜ºï¸\n",
      "output: Got data for your diary? ğŸ˜‰ Come back when you've added some!\n",
      "\n",
      "input: Ok, let me analyse your data some more... ğŸ”\n",
      "output: Analysing your data... â³\n",
      "\n",
      "input: Okay, will be back soon with more info... ğŸ”\n",
      "output: Be right back with more deets soon! ğŸ’»âœ¨\n",
      "\n",
      "input: (Advanced analysis requires time, I'll be back when I'm done...)\n",
      "output: Advanced analysis taking a bit longer â³, be back soon!\n",
      "\n",
      "input: (This may take some time, I'll send you a message when it's done...)\n",
      "output: It's processing â³! I'll let you know when it's finished.\n",
      "\n",
      "input: âš  WARNING:  you're comparing two periods with different lenghts. The comparison might be unsafe.\n",
      "output: âš ï¸ Warning: Comparing periods of different lengths can lead to unreliable results. Be cautious! ğŸ›¡ï¸\n",
      "\n",
      "input: Some days at the beginning and/or end are missing. ğŸ§ \n",
      " \n",
      " I removed these for you: \n",
      " - Mar 01 - Mar 05\n",
      "output: Some initial and/or final days are missing! ğŸ§ \n",
      "\n",
      "I've removed: \n",
      "- Mar 01 - Mar 05 ğŸ’ª\n",
      "\n",
      "input: âš  FOOD: In the chart below you can see how different foods contributes to your intake:\n",
      "output: ğŸ’¡ FOOD: Check out the chart to see how different foods impact your daily intake! ğŸ½ï¸\n",
      "\n",
      "input: âš  TREND: you should get more carbohydrates, but you're slightly decreasing it .\n",
      " It would be better to revert this. ğŸ§ \n",
      "output: âš  TREND: Your carb intake needs a boost! ğŸ \n",
      "Try to eat more of it for better results. ğŸ˜‰\n",
      "\n",
      "input: âš  CONSISTENCY: Your daily intake seems pretty variable: try to eat similar amounts every day. ğŸ§\n",
      "output: âš  Consistency needed! â¡ï¸ Your eating habits seem to change a lot. Aim for more consistent intake throughout the day. ğŸ˜‰\n",
      "\n",
      "input: âœ… TREND: you should get more sodium, in fact you're lightly increasing it .\n",
      " This is the right way to go. â˜ºï¸ \n",
      " \n",
      " âš  CONSISTENCY: I see high variability in your daily intake: you should try to avoid changing it so often ğŸ§\n",
      "output: âœ… Good news! Your sodium intake is on the right track ğŸ’ª. \n",
      "\n",
      "âš  But be consistent! âš ï¸ Your daily intake has been changing a lot lately. Try to keep it more stable for better results. ğŸ˜‰\n",
      "\n",
      "input: âš  TREND: you should keep your actual energy intake, instead you're slightly decreasing it .\n",
      " This is ok for now but better stabilise it to preserve this result ğŸ¤” \n",
      " ğŸ“ˆ PROGRESS: The trend is about the same as before ğŸ¤” \n",
      " \n",
      " âœ… CONSISTENCY: Your daily intake looks regular, good job! ğŸ˜ \n",
      " ğŸ“ˆ PROGRESS: The consistency didn't really change ğŸ¤”\n",
      "output: âš  Energy intake is slightly lower than ideal ğŸ¤”. \n",
      "ğŸ“ˆ Good news, the overall trend is stable! ğŸ˜\n",
      "âœ… Consistent eating habits ğŸ’ª. \n",
      "ğŸ“ˆ Consistency could be slightly better ğŸ˜‰.\n",
      "\n",
      "input: ğŸ– PROTEIN ğŸ– \n",
      " \n",
      " âš  ON AVERAGE: You had 83% (17% deficit). It should be more, we'll have to work on it. ğŸ§\n",
      " \n",
      " \n",
      " âš  TOUGHEST DAY: April 28, your intake was 52% (48% missing). It's not enough, we have to address this. ğŸ§\n",
      "output: ğŸ– PROTEIN ğŸ–\n",
      "\n",
      " âš  Your protein intake isn't hitting the mark! ğŸ’ª\n",
      "\n",
      "- On average, you're falling short by 17%, landing at 83%. ğŸ“‰ Let's work on increasing that! ğŸ‹ï¸â€â™€ï¸\n",
      "- April 28th was your toughest day yet! ğŸ˜¨ Your intake was only 52%, missing 48% of your goal. ğŸ˜± We need to get that back on track! ğŸ¯\n",
      "\n",
      "input: ğŸ¬ SUGAR ğŸ¬ \n",
      " \n",
      " âš  ON AVERAGE: You got 55% (45% missing). You need to increase it, we have to address this. ğŸ¤”\n",
      " \n",
      " \n",
      " âš  TOUGHEST DAY: April 26, your intake was 32% (68% missing). It's not enough, we have to address this. ğŸ¤”\n",
      "output: ğŸ¬ Sugar ğŸ¬\n",
      "\n",
      " âš  ON AVERAGE: You're missing 45% of your target! We need to boost that up. ğŸ¤”\n",
      "\n",
      " âš  APRIL 26th: Your intake was just 32% (68% missing)! Not enough, let's fix this. ğŸ¤”\n",
      "\n",
      "input: ğŸ”¥ ENERGY ğŸ”¥ \n",
      " \n",
      " âœ… ON AVERAGE: I see a good balance in your energy intake. Well done! ğŸ˜ƒ \n",
      " ğŸ“ˆ PROGRESS: The average energy intake is about the same as before ğŸ§ \n",
      " \n",
      " âš  TOUGHEST DAY: April 17, your intake was 51% (49% missing). It's not enough, we have to address this. ğŸ§\n",
      " ğŸ“ˆ PROGRESS: The intake for most off-plan day is about the same as before ğŸ§\n",
      "output: ğŸ”¥ ENERGY ğŸ”¥\n",
      "\n",
      "âœ… Good news! Your average energy intake is balanced ğŸ’ª\n",
      "\n",
      "ğŸ“ˆ But there's room for improvement! Your energy intake on April 17 was only 51% (49% missing) ğŸ™ We need to address this ASAP!\n",
      "\n",
      "ğŸ“ˆ Overall, your off-plan day intake is similar to before ğŸ§\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for message in messages:\n",
    "    generate_ollama_output('gemma:7b', message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rephrasing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
